# JVM、JUC原理总结

## JVM

### 1、JVM内存分为哪几个区？每个区的作用

![JVM内存区域](D:\github\MyKnowledgeRepository\picture\java内存区域.png)



线程私有的：程序计数器、虚拟机栈、本地方法栈

线程共享的：堆、方法区



**程序计数器**

记录正在执行的虚拟机字节码指令的地址



**虚拟机栈**

每个java方法在执行的同时会创建一个栈帧，用于存储局部变量表、操作数栈、常量池引用等信息。

从方法调用直至完成的过程，对应着一个栈帧在java虚拟机栈中入栈和出栈的过程

![**虚拟机栈**](D:\github\MyKnowledgeRepository\picture\java虚拟机栈.png)



**本地方法栈**

本地方法栈和虚拟机栈类似，它们之间的区别是本地方法栈为本地方法服务

本地方法一般是用其他语言(C、C++)编写的，编译为基于本地硬件和操作系统的程序。



**堆**

所有对象都在这里分配内存，是垃圾收集的主要区域

java堆可以细分为：新生代和老年代

新生代还可以细分为：Eden、from survivor、to survivor



**方法区**

用于存放已被加载的类信息、常量、静态变量等信息



虚拟机把它当永久代来进行垃圾回收，但很难确定永久代的大小，因为它受很多因素的影响，每次Full GC后，永久代的大小都会改变，经常抛出OutOfMemoryError的异常。为了更容易管理方法区，从JDK1.8开始，移除永久代，并把方法区移至元空间，它位于本地内存中，而不是虚拟机内存中



![jdk1.8内存区域](D:\github\MyKnowledgeRepository\picture\JDK1.8内存区域.png)



### 2、Java类加载的过程

类加载的过程包括：加载、验证、准备、解析、初始化等5个过程

1. 加载

   加载过程完成三件事情：

   - 通过类的全限定名称获取该类的二进制流
   - 将该二进制流中的静态存储结构转化为方法区运行时的数据结构
   - 在内存中生成该类的class对象，作为该类的数据访问入口

2. 验证

   确保class文件的字节流信息不会危害到虚拟机

3. 准备

   准备阶段是为类变量分配内存并且设置初始值，使用的是方法区的内存。

   实例变量不会在这阶段分配内存，它会在对象实例化时随着对象一起分配在堆中。

   可以发现，实例化不是类加载的过程，类加载发生在所有实例化之前，并且类加载只进行一次，实例化可以进行多次。

4. 解析

   该阶段主要完成符号引用到直接引用的转换动作

5. 初始化

   初始化阶段才是真正执行类中定义的java代码。初始化阶段是虚拟机执行类构造器方法的过程。



### 3、垃圾收集算法

1. **标记-清除**

   该算法分为“标记”和“清除”阶段，首先标记出所有不需要清除的对象，在标记完成后同一回收掉没有被标记的对象。

   不足：

   标记和清除的过程效率不高

   会产生大量不连续内存碎片

   ![标记清除](D:\github\MyKnowledgeRepository\picture\标记清除算法.png)

   

2. **标记-整理**

   把所有存活的对象移到一端，然后清理掉端边界的以外的所有内存

   优点：不会产生内存碎片

   缺点：需要移动大量对象，处理效率比较低

   ![标记整理](D:\github\MyKnowledgeRepository\picture\标记整理算法.png)

   

3. **标记-复制**

   将内存分为大小相同的两块，每次使用其中一块。当一块内存使用完之后，将存活的对象复制到另一块，然后把使用过的内存空间清理掉

   主要不足是只使用了内存的另一半

   ![标记复制](D:\github\MyKnowledgeRepository\picture\标记复制算法.png)

   

   

4. **分代收集**

   它根据对象存活周期将内存分为几块，不同块采用适当的收集算法

   一般将堆分为新生代和老年代

   - 新生代：使用标记-复制算法
   - 老年代：使用标记-清除或标记-整理

   

### 4、如何判断对象是否存活

**1、引用计数算法**

为对象添加一个引用计数器，每当有一个地方引用它，计数器加1；当引用失效，计数器减1。计数为0时，对象可回收。

优点：简单、高效

缺点：很难解决对象之间相互引用的问题

**2、可达性分析算法**

以GC Roots为起始点进行搜索，可到达的对象都是存活的，不可达到的对象可被回收的

![可达性分析算法](D:\github\MyKnowledgeRepository\picture\可达性分析算法.png)





### 5、什么是类加载器，类加载器有哪些？

通过类的全限定名获取类的二进制字节流的代码块叫做类加载器



主要有以下四类加载器：

1. 启动类加载器。用于加载java的核心类库，无法被java程序直接引用
2. 扩展类加载器。用于加载java的扩展类库
3. 系统类加载器。也叫应用类加载器。它根据java应用的类路径来加载java类
4. 用户自定义加载器。通过继承java.lang.ClassLoader类的方式来实现



### 6、Java内存分配与回收策略(Minor GC和Full GC)

Minor GC：回收新生代。新生代对象存活时间很短，因此Minor GC会频繁执行，执行速度一般比较快

Full GC：回收老年代和新生代。老年代对象存活时间长，因此Full GC很少执行，执行速度比Minor GC慢很多



**内存分配和回收**

1. **对象优先在Eden分配**
   - 大多数情况下，对象都是在新生代Eden上分配，当Eden空间不足，发起Minor GC
2. **大对象直接进入老年代**
   - 大对象是指需要连续内存的空间对象，比如很长的字符串或者数组
   - 经常出现大对象会提前触发垃圾收集，以获得足够的连续空间分配给大对象
   - 可以设置此值，大于此值的对象直接进入老年代，避免在Eden和Survivor之间大量内存复制
3. **长期存活对象进入老年代**
   - 为对象定义一个年龄计数器，对象经过Eden出生以及Minor GC依然存活，移动到Survivor区，年龄加1。增加到一定年龄，移动到老年代。
4. **动态对象年龄判定**
   - 不是非要对象达到指定年龄才能进入老年代，如果Survivor中相同年龄的所有对象，大小总和大于Survivor空间的一半，则年龄大于或等于该年龄的对象可以直接进入老年代，无需达到指定的年龄。
5. **空间担保机制**
   - 在发生Minor GC前，如果老年代的内存空间不能担保发生Minor GC安全的话，那么就进行Full GC，清理老年代的内存空间。



## JUC

### 1、Synchronized与Lock(ReentrantLock)的区别

1. Synchronized能实现的功能，Lock都能实现，而且Lock比Synchronized更好用更灵活
2. Synchronized可以自动上锁和解锁，Lock需要手动上锁和解锁
3. synchronized是非公平锁，ReentrantLock可以设置为公平锁
4. ReentrantLock上等待获取锁的线程是可中断的，线程可以放弃等待锁。而synchonized会无限期等待下去。



### 2、Runnable和Callable的区别

1. Runnable的方法是run()，Callable接口方法是call()
2. Runnable接口没有返回值，Callable接口有返回值
3. Runnable接口的方法没有抛出异常，Callable接口的方法抛出异常



### 3、什么是分布式？分布式CAP理论是什么？

分布式是通过网络交换信息，彼此相互协作而形成的系统。



CAP理论是指在分布式系统中，一致性、可用性、分区容错性三者不可兼得

一致性是指在分布式所有数据备份中，在同一时刻是否同样的值。

可用性是指集群一部分节点出现故障后，集群整体是否还能响应客户端的读写请求。

分区容错是指区间通信可能失败，系统不能在时限内保持数据一致性。



### 4、什么是分布式锁？

在分布式模型下，数据只有一份，此时需要利用锁技术控制某一时刻修改数据的进程数。

分布式与单机最大的不同不是多线程而是多进程。

多线程可以共享堆内存，可以采取内存作为标记存储的位置。

而进程之间可能不再同一台主机上，因此分布式锁可以标记在所有进程都可以看到的公共内存，比如Redis、Memcache。

与单机模式下的锁不同，分布式锁不仅要考虑进程可见性，还要考虑进程与锁之间的网络通信问题。



### 5、什么是分布式事务？

分布式事务是指事务的参与者分别位于分布式系统的不同节点上。

简单地说就是一次大的操作由不同的小操作组成，这些小的操作分布在不同的服务器上，分布式事务需要保证这些小的操作要么全部成功，要么全部失败。

本质上来说，分布式事务就是保证不同数据库的数据一致性。



### 6、线程池

#### 为什么使用线程池

池化技术的主要思想是减少每次获取资源的消耗，提高对资源的利用率。

#### 线程池实现原理

一个线程集合workset和一个阻塞队列workqueue，当用户向线程池提交一个任务时（也就是线程），线程池会先将任务放到workqueue中，workset中的线程会不断地从workqueue中获取任务然后执行。当workqueue中没有任务的时候，worker就会阻塞，直到队列中有了任务就取出来继续执行。

![线程池实现原理](D:\github\MyKnowledgeRepository\picture\线程池实现原理.png)



#### 线程池几个主要参数

```java
public ThreadPoolExecutor(int corePoolSize,
                          int maximumPoolSize,
                          long keepAliveTime,
                          TimeUnit unit,
                          BlockingQueue<Runnable> workQueue,
                          ThreadFactory threadFactory,
                          RejectedExecutionHandler handler)

```

**corePoolSize**：规定线程池有几个核心线程在运行

**maximumPoolSize**：当WorkQueue满时，不能添加任务时，这个参数才生效。规定线程池最多只能有几个线程在执行

**keepAliveTime**：超过corePoolSize大小的那些线程的生存时间，如果这些线程长时间没有执行任务并且超过keepAliveTime设定的时间，就会消亡。

**unit**：keepAliveTime参数的时间单位

**workQueue**：存放任务的队列

**threadFactory**：创建线程的工厂

**handler**：当workQueue已满，并且线程池已经达到maximumPoolSize，执行拒绝策略

 

#### 线程池工作流程

用户提交一个任务，线程池执行如下流程：

1. 判断核心线程池是否已满，如果未满，创建一个核心线程执行该任务。
2. 如果核心线程已满，将任务加入到队列中。
3. 如果队列已满，判断线程池是否已满，如果未满就创建非核心线程执行任务。
4. 如果线程池已满，采用拒绝策略。

![线程池工作流程](D:\github\MyKnowledgeRepository\picture\线程池工作流程.png)





#### 线程池种类（java自带哪几种线程池）

- newSingleThreadExecutor。创建唯一的工作线程执行任务。单工作线程最大的特点是可保证顺序地执行各个任务。
- newFixedThreadPool。创建指定线程数的线程池。该线程池节省了创建线程时的开销，但是当线程池没有可运行任务时，它不会释放工作线程，还会占用一定的系统资源
- newCachedThreadPool。创建一个可缓存线程池。它可灵活地回收空闲线程，若无可回收，则创建新线程。它的特点是可灵活的往线程池中添加线程。
- newScheduleThreadPool。该线程池可以指定延迟多少时间执行或者周期性执行



#### 线程池的状态

**Running**

接收新任务，也能处理阻塞队列里的任务

线程池初始状态为running状态



**ShutDown**

不接收新的任务，但是处理阻塞队列里的任务

调用shutdown接口，线程池由running -> shutdown



**Stop**

不接收新任务，不处理阻塞队列里的任务，并且会中断正在处理的任务

调用shutdownnow接口，线程池 由running或shutdown -> stop



**Tidying**

当所有的任务已经执行完，当前线程池已经没有工作线程，这时线程池会变为tidying状态，并且调用terminated()

当线程池处于shutdown状态，阻塞队列为空，并且线程池中执行的任务也为空，就会由shutdown -> tidying

当线程池处于stop状态，线程池中执行的任务为空，就会由stop -> tidying



**Terminated**

线程池彻底终止

线程池处于tidying状态，执行完terminated()方法之后，就会由tidying -> terminated



![线程池状态](D:\github\MyKnowledgeRepository\picture\线程池状态.png)



### 7、线程中断了解吗？

线程中断即线程运行过程中被其他线程给打断了，它与 stop 最大的区别是：stop 是由系统强制终止线程，而线程中断则是给目标线程发送一个中断信号，如果目标线程正在执行并且接收到中断信号后，是结束线程还是执行其他取决于目标线程。如果目标线程是通过调用wait()、sleep()、join()方式进入阻塞状态的，则会抛出异常。

它有三个重要方法：

1.interrupt()。调用目标线程的interrupt()方法，给目标线程发一个中断信号，线程被打上中断标记。

2.isInterrupted()。判断目标线程是否被中断，不会清除中断标记。

3.interrupted()。判断目标线程是否被中断，会清除中断标记。



### 8、volatile

volatile是轻量级同步机制，它能保证变量对所有线程的可见行，但不能保证原子性。

他有两个作用：1.可见行 2.禁止指令重排序

它的原理是：

1.当对volatile变量进行写操作时，会将缓存的数据写回给内存

2.由于缓存一致性协议，其他线程发现数据被修改了，会重新从内存中读取数据到缓存中



### 9、Synchronized

它可以修改普通方法、静态方法，也可以修改代码块；



它的作用：

1.原子性。可以确保线程互斥的访问代码

2.可见行。保证共享变量的修改能够及时可见

3.有序性。解决了重排序问题



它的原理：

synchronized 同步代码块的实现是通过 monitorenter 和 monitorexit 指令，其中 monitorenter 指令指向同步代码块的开始位置，monitorexit 指令则指明同步代码块的结束位置。当执行 monitorenter 指令时，线程试图获取锁也就是获取 monitor的持有权（monitor对象存在于每个Java对象的对象头中， synchronized 锁便是通过这种方式获取锁的，这也是为什么Java中任意对象可以作为锁的原因）。

其内部包含一个计数器，当计数器为0则可以成功获取，获取后将锁计数器设为1也就是加1。相应的在 执行 monitorexit 指令后，将锁计数器设为0，表明锁被释放。如果获取对象锁失败，那当前线程就要阻塞等待，直到锁被另外一个线程释放为止



### 10、ReentrantLock

ReentrantLock是基于AQS的，在并发编程中它可以实现公平锁和非公平锁来实现对共享资源的同步，并且它支持可重入。



可重入：单个线程执行时，重新进入一个子程序，任然是线程安全的。

可以这么理解，线程A在某上下文中获取了某锁，当线程A想要再次获取锁时，不会因为锁已经被自己占用，而需要等待锁的释放。假如线程A既获得了锁，又在等待自己释放锁，那么就会造成死锁。

可重入性简单地来说，就是一个线程可以不用释放而重复地获取一个锁n次，只是在释放的时候也需要相应的释放n次。



公平锁：按照请求锁的顺序分配，拥有稳定获得锁的机会，但是性能可能比非公平锁低

非公平锁：不按照请求锁的顺序分配，不一定拥有获得锁的机会，但是性能可能比公平锁高

非公平锁意味着后请求锁的线程，可能在前面的休眠线程恢复前拿到锁，这样就可能提高并发的性能，这是因为通常情况下，你去唤醒一个挂起的线程，线程切换之间会产生短暂的延时，非公平锁就可以利用这段时间来完成操作，这也就是为什么非公平锁在一些情况下比公平锁性能高的原因。



**它是如何实现可重入的？**

ReentrantLock 内部自定义了同步器 Sync，在加锁的时候通过 CAS 算法，将线程对象放到一个双向链表中，每次获取锁的时候，检查当前维护的那个线程 ID 和当前请求的线程 ID 是否 一致，如果一致，同步状态加1，表示锁被当前线程获取了多次



### 11、volatile和synchronized的区别

1. volatile只能使用在变量上；而synchronized可以在类，变量，方法和代码块上。
2. volatile只保证可见性；synchronized保证原子性与可见性。



### 12、CAS原理

CAS全称 Compare And Swap，比较与交换，是乐观锁的主要实现方式。CAS 在不使用锁的情况下实现多线程之间的变量同步。ReentrantLock 内部的 AQS 和原子类内部都使用了 CAS。

CAS 的思想很简单：三个参数，一个当前内存值 V、旧的预期值 A、即将更新的值 B，只有当 V 的值等于 A 时，才会使用原子方式用新值B来更新V的值，否则会继续重试直到成功更新值。

以 AtomicInteger 为例，AtomicInteger 的 getAndIncrement()方法底层就是CAS实现，关键代码是 `compareAndSwapInt(obj, offset, expect, update)`，其含义就是，如果`obj`内的`value`和`expect`相等，就证明没有其他线程改变过这个变量，那么就更新它为`update`，如果不相等，那就会继续重试直到成功更新值。



**CAS存在的问题**

1、ABA问题。CAS需要在操作值的时候检查内存值是否发生变化，没有发生变化才会更新内存值。但是如果内存值原来是A，后来变成了B，然后又变成了A，那么CAS进行检查时会发现值没有发生变化，但是实际上是有变化的。ABA问题的解决思路就是在变量前面添加版本号，每次变量更新的时候都把版本号加一，这样变化过程就从`A－B－A`变成了`1A－2B－3A`

2、循环时间长开销大。CAS操作如果长时间不成功，会导致其自旋，给cpu带来非常大的开销

3、只能保证一个共享变量的原子操作。对一个共享变量执行操作时，CAS能够保证原子操作，但是对多个共享变量操作时，CAS是无法保证操作的原子性的。Java从1.5开始JDK提供了AtomicReference类来保证引用对象之间的原子性，可以把多个变量放在一个对象里来进行CAS操作。



### 13、AQS原理

AQS是抽象队列同步器，定义了一套多线程访问共享资源的同步器框架。

它使用了volatile修饰的int类型变量state，来表示同步状态，通过CAS修改同步状态的值。当线程调用lock方法时，如果state=0，说明没有任何线程占有共享资源的锁，可以获得锁并将state加1（共享模式下）；如果state不为0，则说明线程正在使用共享变量，其他线程必须加入同步队列进行等待。

同步队列是一个先进先出的双向队列，当前线程获取同步状态失败时，同步器会将当前状态构造一个节点(Node)并将其加入同步队列进行自旋，当同步状态释放时，会把首节点的后继节点线程唤醒（首节点是一个虚节点），使其再次获取同步状态！



AQS独占模式，锁只能被单个节点占用。它只会把将要出队的节点线程唤醒。

AQS共享模式，锁可以被多个节点占用。除了唤醒将要出队的节点线程，还会唤醒后续的处于挂起状态的节点。



### 14、CountDownLatch、CyclicBarrier和Semaphore

**CountDownLatch**

CountDownLatch是一个同步工具，它允许一条或多条线程等待其他线程中的一组操作完成后，再继续执行。

原理：CountDownLatch也是基于AQS操作的，初始化时会指定同步任务状态state被占用几次，子任务完成任务后释放锁，state-1，当state=0时，主任务唤醒



**CyclicBarrier**

CyclicBarrier(同步屏障)，可以使一定数量的线程全部等待到某一个状态，然后这组线程再同时执行。

适用场景：用于多线程计算数据，最后合并计算结果的场景。



**CyclicBarrier和CountDownLatch区别**

两者都能实现线程之间的等待。

CountDownLatch用于某个线程等待其他线程执行完任务再执行。CyclicBarrier用于一组线程互相等待到某个状态，然后这组线程再同时执行。

CountDownLatch的计数器只能使用一次，而CyclicBarrier的计数器可以使用reset()方法重置，可用于处理更为复杂的业务场景。



**Semaphore**

Semaphore类似于锁，它维护了一定数量的“许可证”，当有线程访问共享资源的时候，首先就要去获得“许可证”，如果许可证不够了，线程就会等待，直到获得许可证。线程使用完资源会释放“许可证”



### 15、ThreadLocal

线程本地变量。当使用ThreadLocal维护变量时，ThreadLocal为每个使用该变量的线程提供了独立的变量副本，所以每个线程都可以独立地改变自己的副本，而不会影响其他线程



**原理**

每个线程都有一个ThreadLocalMap，Map中的元素的键为ThreadLocal，值对应线程的变量副本。

调用threadlocal.set() -> 调用getMap(Thread) -> 返回当前线程的ThreadLocalMap<ThreadLocal,value> -> 如果ThreadLocalMap不为空，则调用map.set(this,value)，this就是ThreadLocal；如果ThreadLocalMap为空，则创建ThreadLocalMap

源码：

```java
public void set(T value) {
    Thread t = Thread.currentThread();
    ThreadLocalMap map = getMap(t);
    if (map != null)
        map.set(this, value);
    else
        createMap(t, value);
}

ThreadLocalMap getMap(Thread t) {
    return t.threadLocals;
}

void createMap(Thread t, T firstValue) {
    t.threadLocals = new ThreadLocalMap(this, firstValue);
}
```



**ThreadLocal内存泄漏的原因**

每个ThreadLocal有一个内部类ThreadLocalMap，map的key是ThreadLocal，定义为弱引用，value是强引用。弱引用的话，GC的时候会自动回收，而强应用的回收取决于对象的生命周期。这就导致GC的时候会自动回收key，而value会跟随Thread的生命周期。一般线程是通过线程池的方式来复用，这也导致Thread生命周期比较长（Thread --> ThreadLocalMap-->Entry-->Value），随着任务的执行，value就有可能越来越多且无法释放，最终导致内存泄漏。

解决办法：每次使⽤完ThreadLocal就调⽤它的remove()⽅法，手动将对应的键值对删除，从⽽避免内存泄漏。



**适用场景**

当我们只想在本身的线程内使用的变量，并且变量是和线程的生命周期相关联，可以用ThreadLocal来实现。

ThreadLocal 不是为了解决线程间的共享变量问题的，如果是多线程都需要访问的数据，那需要用全局变量加同步机制。

比如Java web应用中，每个线程有自己单独的 Session 实例，就可以使用ThreadLocal来实现



### 16、锁

**公平锁和非公平锁**

synchronized 是非公平锁， Lock 默认是非公平锁，可以设置为公平锁。



公平锁：按照请求锁的顺序分配，拥有稳定获得锁的机会，但是性能可能比非公平锁低

非公平锁：不按照请求锁的顺序分配，不一定拥有获得锁的机会，但是性能可能比公平锁高



非公平锁意味着后请求锁的线程，可能在前面的休眠线程恢复前拿到锁，这样就可能提高并发的性能，这是因为通常情况下，你去唤醒一个挂起的线程，线程切换之间会产生短暂的延时，非公平锁就可以利用这段时间来完成操作，这也就是为什么非公平锁在一些情况下比公平锁性能高的原因。



**共享锁和独占锁**

它们之间最大的区别：同一时刻独占锁只能有一个线程获取同步状态，而共享锁在同一时刻可以有多个线程获取同步状态



**悲观锁和乐观锁**

悲观锁，每次访问资源都会加锁，执行完同步代码释放锁，synchronized 和 ReentrantLock 属于悲观锁。

乐观锁，不会锁定资源，所有的线程都能访问并修改同一个资源，如果没有冲突就修改成功并退出，否则就会继续循环尝试。乐观锁最常见的实现就是CAS。



适用场景：悲观锁适合写操作比较多的时候，乐观锁适合读操作多的时候。



乐观锁有什么缺点？

乐观锁最常见的实现就是CAS，所以CAS存在的问题也是目前乐观锁存在的问题。

乐观锁避免了悲观锁独占对象的现象，提高了并发性能，但它也有缺点：

1.乐观锁只能保证一个共享变量的原子操作。如果有多个共享变量，乐观锁会显得力不从心

2.乐观锁如果长时间自旋，会导致cpu开销大

3.造成ABA的问题





