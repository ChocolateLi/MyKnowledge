# 大数据环境搭建

# Hadoop单机伪分布式集群搭建

## 1.准备linux环境

1. 关闭防火墙

2. 创建用户和组

   ```shell
   # hadoop缩写hdp
   useradd hadoop
   groupadd hadoop
   ```

3. 修改主机和ip的映射关系

```shell
127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4
::1         localhost localhost.localdomain localhost6 localhost6.localdomain6
10.201.100.75 cesdb hadoop
```

4.配置集群（单节点）互信

```shell
# 切换hadoop用户
su hadoop

# 生成公钥
ssh-keygen -t rsa

# 复制公钥
cat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys
chmod 600 ~/.ssh/authorized_keys

# 重启ssh
systemctl restart sshd

# 测试
ssh localhost
ssh cesdb
ssh hadoop
```

## 2.安装jdk

将jdk的包上上传到需要的目录然后解压到相应的目录上，我的jdk目前解压到了/usr/jdk中

将java添加到环境变量中

```shell
vim /etc/profile

# JAVA_HOME
JAVA_HOME=/usr/jdk
PATH=$JAVA_HOME/bin:$PATH
CLASSPATH=:.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar
export JAVA_HOME
export PATH
export CLASSPATH
# HADOOP_HOME
export HADOOP_HOME=/data/u01/app/hadoop/hadoop-3.3.6
export PATH=$PATH:$HADOOP_HOME/bin
export PATH=$PATH:$HADOOP_HOME/sbin

#刷新配置
source /etc/profile
```

## 3.安装hadoop - 3.3.6

1. 从官网下载[下载hadoop-3.3.6](https://www.apache.org/dyn/closer.cgi/hadoop/common/hadoop-3.3.6/hadoop-3.3.6.tar.gz)

2. 将文件上传到 /data/u01/soft

3. 解压文件

   ```shell
   tar -zxvf hadoop-3.3.6 -C /data/u01/app/hadoop
   ```

4. 配置hadoop文件

   第一个：hadoop-env.sh

   ```shell
   cd /data/u01/app/hadoop/hadoop-3.3.6/etc/hadoop
   
   vim hadoop-env.sh
   
   export JAVA_HOME=/usr/jdk
   export HADOOP_LOG_DIR=${HADOOP_HOME}/logs
   ```

   第二个：core-site.xml

   ```shell
   <configuration>
           <property>
                   <name>fs.defaultFS</name>
                   <value>hdfs://cesdb:8020</value>
                   <description>hdfs内部通讯访问地址</description>
           </property>
           <property>
                   <name>hadoop.tmp.dir</name>
                   <value>/data/u01/app/hadoop/hadoop-3.3.6/data/tmp</value>
           </property>
           <property>
                   <name>hadoop.proxyuser.hadoop.hosts</name>
                   <value>*</value>
           </property>
           <property>
                   <name>hadoop.proxyuser.hadoop.groups</name>
                   <value>*</value>
           </property>     
   </configuration>
   
   ```

   第三个：hdfs-site.xml

   ```shell
   <configuration>
   
     <property>
         <name>dfs.namenode.name.dir</name>
         <value>/data/u01/app/hadoop/hadoop-3.3.6/data/namenode</value>
         <description> namenode 存放name table(fsimage)本地目录需要修改,如果没有需要自己创建文件目录)</description>
     </property>
     <property>
         <name>dfs.datanode.data.dir</name>
         <value>/data/u01/app/hadoop/hadoop-3.3.6/data/datanode</value>
         <description>datanode存放block本地目录（需要修改,如果没有需要自己创建文件目录）</description>
     </property>
     <property>
             <!--由于只有一台机器,hdfs的副本数就指定为1-->
             <name>dfs.replication</name>
             <value>1</value>
      </property>
      <property>
       <name>dfs.permissions.enabled</name>
       <value>false</value>
   </property>
   
   </configuration>
   
   ```

   第四个：mapred-site.xml

   ```shell
   <configuration>
           <!-- 指定mr运行在yarn上 -->
           <property>
                   <name>mapreduce.framework.name</name>
                   <value>yarn</value>
           </property>
   </configuration>
   ```

   第五个：yarn-site.xml

   ```shell
   <configuration>
   
       <!-- Site specific YARN configuration properties -->
       <!-- 指定YARN的老大（ResourceManager）的地址 -->
       <property>
            <name>yarn.resourcemanager.hostname</name>
            <value>cesdb</value>
       </property>
       <!-- reducer获取数据的方式 -->
       <property>
            <name>yarn.nodemanager.aux-services</name>
            <value>mapreduce_shuffle</value>
       </property>
       <!-- ResourceManager Web UI Port Configuration -->
         <property>
           <name>yarn.resourcemanager.webapp.address</name>
           <value>cesdb:8082</value>
           <description>Address where the ResourceManager web application will listen on.</description>
         </property>
       <property>
           <name>yarn.nodemanager.aux-services.mapreduce.shuffle.class</name>
           <value>org.apache.hadoop.mapred.ShuffleHandler</value>
         </property>
         <property>
           <name>yarn.application.classpath</name>
           <value>$HADOOP_HOME/etc/hadoop:$HADOOP_HOME//share/hadoop/common/lib/*:$HADOOP_HOME//share/hadoop/common/*:$HADOOP_HOME//share/hadoop/hdfs:$HADOOP_HOME//share/hadoop/hdfs/lib/*:$HADOOP_HOME//share/hadoop/hdfs/*:$HADOOP_HOME//share/hadoop/mapreduce/lib/*:$HADOOP_HOME//share/hadoop/mapreduce/*:$HADOOP_HOME//share/hadoop/yarn:$HADOOP_HOME//share/hadoop/yarn/lib/*:$HADOOP_HOME//share/hadoop/yarn/*</value>
         </property>
   </configuration>
   
   ```

5. 第一个启动集群需要格式化namenode

   ```shell
   hdfs namenode -format
   ```

6. 启动hadoop

   ```shell
   # 先启动HDFS
   sbin/start-dfs.sh
   
   # 再启动YARN
   sbin/start-yarn.sh
   
   # jps验证是否成功
   [hadoop@cesdb logs]$ jps
   85961 Jps
   191593 DataNode
   192825 SecondaryNameNode
   225583 ResourceManager
   191372 NameNode
   225836 NodeManager
   ```

7. 访问

   ```shell
   http://10.201.100.75:9870（HDFS管理界面）
   http://10.201.100.75:8082 （MR管理界面）
   ```

# Hive搭建

在已经搭建好的 Hadoop 环境中安装和配置 Hive，并使用 Oracle 作为元数据存储，需要进行以下步骤：

## 1. 下载和安装 Hive
首先，从 Apache 官网下载 Hive，并进行安装：

```bash
# 下载 Hive
wget https://downloads.apache.org/hive/hive-3.1.3/apache-hive-3.1.3-bin.tar.gz

# 解压缩 Hive
tar -xzvf apache-hive-3.1.3-bin.tar.gz -C /data/u01/soft/hive
```

## 2. 配置环境变量
配置 Hive 的环境变量：

```bash
vim /etc/profile
```

在文件末尾添加以下内容：

```bash
# Hive environment variables
export HIVE_HOME=/data/u01/app/hive/apache-hive-3.1.3
export PATH=$PATH:$HIVE_HOME/bin
```

使环境变量生效：

```bash
source /etc/profile
```

## 3. 下载并配置 Oracle JDBC 驱动
从 Oracle 官网下载 Oracle JDBC 驱动（例如 `ojdbc8.jar`），然后将其复制到 Hive 的 lib 目录：

```bash
cp /path/to/ojdbc8.jar $HIVE_HOME/lib/
```

## 4. 配置 Hive 使用 Oracle 作为元数据存储

创建一个日志文件夹

```shell
mkdir logs
```

进入配置文件夹

```shell
cd /data/u01/app/hive/apache-hive-3.1.3/conf

touch hive-site.xml
cp hive-env.sh.template hive-env.sh
# 不手动添加的话,hive不打印日志！！！
cp hive-log4j2.properties.template hive-log4j2.properties
cp hive-exec-log4j2.properties.template hive-exec-log4j2.properties
```

修改hive-env.sh

```shell
vim hive-env.sh

HADOOP_HOME=/data/u01/app/hadoop/hadoop-3.3.6
```

编辑 Hive 的配置文件 `hive-site.xml`：

```bash
vim hive-site.xml
```

添加以下配置：

```xml
<configuration>
   <!--
	//oracle服务的方式
	jdbc:oracle:thin:@//199.168.200.55:1521/docare

	//oracle sid的方法是
	jdbc:oracle:thin:@10.201.100.75:1521:cesdb
	--> 
    
  <!-- Oracle JDBC connection string -->
  <property>
    <name>javax.jdo.option.ConnectionURL</name>
    <value>jdbc:oracle:thin:@10.201.100.75:1521:cesdb</value>
    <description>JDBC connect string for a JDBC metastore</description>
  </property>

  <property>
    <name>javax.jdo.option.ConnectionDriverName</name>
    <value>oracle.jdbc.OracleDriver</value>
    <description>Driver class name for a JDBC metastore</description>
  </property>

  <property>
    <name>javax.jdo.option.ConnectionUserName</name>
    <value>用户名</value>
    <description>Username to use against metastore database</description>
  </property>

  <property>
    <name>javax.jdo.option.ConnectionPassword</name>
    <value>密码</value>
    <description>Password to use against metastore database</description>
  </property>


  <!-- Hive Execution Configuration -->
  <property>
    <name>hive.execution.engine</name>
    <value>mr</value>
    <description>Execution engine to use. mr is mapreduce, tez is Tez, spark is Spark</description>
  </property>
    
    <property>
        <!--hive表在hdfs的位置-->
        <name>hive.metastore.warehouse.dir</name>
        <value>/user/hive/warehouse</value>
    </property>
    <property>
        <name>hive.security.authorization.enabled</name>
        <value>false</value>
    </property>
    <property>
        <name>hive.security.authorization.createtable.owner.grants</name>
        <value>ALL</value>
    </property>
    <property>
        <name>hive.server2.enable.doAs</name>
        <value>false</value>
    </property>
    <property>
  		<name>hive.metastore.partition.management.task.frequency</name>
  		<value>1d</value>
 		 <description>Frequency at which the partition management task runs to add partitions.</description>
	</property>

</configuration>
```

## 5. 初始化 Hive Metastore
先给Hadoop配置init-env.sh

```shell
cd /data/u01/app/hadoop/hadoop-3.3.6/etc/hadoop

touch init-env.sh

vim init-env.sh

#!/bin/bash
# 添加新的环境变量
export HADOOP_HOME=/data/u01/app/hadoop/hadoop-3.3.6
export HADOOP_CONF_DIR=$HADOOP_HOME/conf
export HADOOP_LOG_DIR=/data/u01/app/hadoop/hadoop-3.3.6/logs
export PATH=$PATH:$HADOOP_HOME/bin

source init-env.sh
```

给Hive配置init-env.sh

```shell
cd /data/u01/app/hive/apache-hive-3.1.3/conf

touch init-env.sh

vim init-env.sh

#!/bin/bash
export HIVE_HOME=/data/u01/app/hive/apache-hive-3.1.3
export HIVE_CONF_DIR=$HIVE_HOME/conf
export PATH=$PATH:$HIVE_HOME/bin

source init-env.sh
```

配置hive启动脚本

启动hive，注：`一定要确保hadoop已经成功启动，才能启动hive，否则连接hive beeline会卡死但是不报错！！！`

```shell
cd /data/u01/app/hive/apache-hive-3.1.3/bin

touch start-all.sh

#!/bin/bash
nohup $HIVE_HOME/bin/hive --service metastore &
nohup $HIVE_HOME/bin/hive --service hiveserver2 &

chmod -R 777 start-all.sh 
```

配置hive停止脚本

```shell
touch stop-all.sh

jps | grep RunJar | awk '{print $1}' | xargs kill -9

chmod -R 777 stop-all.sh 
```

你需要使用 `schematool` 来初始化 Hive Metastore 的 schema：

```bash
schematool -dbType oracle -initSchema
```

## 6. 启动 Hive
现在你可以启动 Hive 并进入 Hive 命令行界面：

```bash
sh start-all.sh
```

判断linux端口使用是否已经监听

```shell
[hadoop@cesdb bin]$ netstat -ntulp |grep 9083
(Not all processes could be identified, non-owned process info
 will not be shown, you would have to be root to see it all.)
tcp6       0      0 :::9083                 :::*                    LISTEN      120633/java         
[hadoop@cesdb bin]$ ps -ef | grep 120633
hadoop   120633      1  8 09:35 pts/11   00:00:15 /usr/jdk/bin/java -Dproc_jar -Dproc_metastore -Dlog4j2.formatMsgNoLookups=true -Dlog4j.configurationFile=hive-log4j2.properties -Djava.util.logging.config.file=/data/u01/app/hive/apache-hive-3.1.3/conf/parquet-logging.properties -Dyarn.log.dir=/data/u01/app/hadoop/hadoop-3.3.6/logs -Dyarn.log.file=hadoop.log -Dyarn.home.dir=/data/u01/app/hadoop/hadoop-3.3.6 -Dyarn.root.logger=INFO,console -Djava.library.path=/data/u01/app/hadoop/hadoop-3.3.6/lib/native -Xmx256m -Dhadoop.log.dir=/data/u01/app/hadoop/hadoop-3.3.6/logs -Dhadoop.log.file=hadoop.log -Dhadoop.home.dir=/data/u01/app/hadoop/hadoop-3.3.6 -Dhadoop.id.str=hadoop -Dhadoop.root.logger=INFO,console -Dhadoop.policy.file=hadoop-policy.xml -Dhadoop.security.logger=INFO,NullAppender org.apache.hadoop.util.RunJar /data/u01/app/hive/apache-hive-3.1.3/lib/hive-metastore-3.1.3.jar org.apache.hadoop.hive.metastore.HiveMetaStore
hadoop   128822 191526  0 09:37 pts/11   00:00:00 grep --color=auto 120633
[hadoop@cesdb bin]$ netstat -ntulp | grep 10000
(Not all processes could be identified, non-owned process info
 will not be shown, you would have to be root to see it all.)
tcp6       0      0 :::10000                :::*                    LISTEN      120634/java         
[hadoop@cesdb bin]$ ps -ef | grep 120634
hadoop   120634      1 11 09:35 pts/11   00:00:27 /usr/jdk/bin/java -Dproc_jar -Dproc_hiveserver2 -Dlog4j2.formatMsgNoLookups=true -Dlog4j.configurationFile=hive-log4j2.properties -Djava.util.logging.config.file=/data/u01/app/hive/apache-hive-3.1.3/conf/parquet-logging.properties -Djline.terminal=jline.UnsupportedTerminal -Dyarn.log.dir=/data/u01/app/hadoop/hadoop-3.3.6/logs -Dyarn.log.file=hadoop.log -Dyarn.home.dir=/data/u01/app/hadoop/hadoop-3.3.6 -Dyarn.root.logger=INFO,console -Djava.library.path=/data/u01/app/hadoop/hadoop-3.3.6/lib/native -Xmx256m -Dhadoop.log.dir=/data/u01/app/hadoop/hadoop-3.3.6/logs -Dhadoop.log.file=hadoop.log -Dhadoop.home.dir=/data/u01/app/hadoop/hadoop-3.3.6 -Dhadoop.id.str=hadoop -Dhadoop.root.logger=INFO,console -Dhadoop.policy.file=hadoop-policy.xml -Dhadoop.security.logger=INFO,NullAppender org.apache.hadoop.util.RunJar /data/u01/app/hive/apache-hive-3.1.3/lib/hive-service-3.1.3.jar org.apache.hive.service.server.HiveServer2
hadoop   131711 191526  0 09:39 pts/11   00:00:00 grep --color=auto 120634

```



## 7. 测试 Hive

在 Hive 命令行中运行一些基本命令来验证 Hive 的安装：

这是第一台客户端（已经不用了）

```sql
hive

CREATE TABLE test_table (id INT, name STRING);

SHOW TABLES;

INSERT INTO test_table (id, name) VALUES (1, 'Alice'), (2, 'Bob');

select * from test_table;
```

如果这些命令成功执行并返回结果，说明 Hive 安装和配置成功。

第二代客户端 beeline

HiveServer2通过Metastore服务读写元数据。所以在远程模式下，启动HiveServer2之前必须先启动metastore服务。

远程模式下，Beeline客户端只能通过HiveServer2服务访问Hive，而bin/hive是通过Metastore服务访问的，关系如下：

![](D:\Github\MyKnowledgeRepository\img\DW_img\Hive客户端和服务的关系.png)

```shell
cd $HIVE_HOME/bin

beeline
!connect jdbc:hive2://主机名:10000
然后输入用户名和密码

beeline> !connect jdbc:hive2://cesdb:10000
Connecting to jdbc:hive2://cesdb:10000
Enter username for jdbc:hive2://cesdb:10000: hadoop
Enter password for jdbc:hive2://cesdb:10000: ******
Connected to: Apache Hive (version 3.1.3)
Driver: Hive JDBC (version 3.1.3)
Transaction isolation: TRANSACTION_REPEATABLE_READ
0: jdbc:hive2://cesdb:10000> select * from test_table;
INFO  : Compiling command(queryId=hadoop_20240612155511_de96a975-0b0b-4766-8b7e-d9ce68587494): select * from test_table
INFO  : Concurrency mode is disabled, not creating a lock manager
INFO  : Semantic Analysis Completed (retrial = false)
INFO  : Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:test_table.id, type:int, comment:null), FieldSchema(name:test_table.name, type:string, comment:null)], properties:null)
INFO  : Completed compiling command(queryId=hadoop_20240612155511_de96a975-0b0b-4766-8b7e-d9ce68587494); Time taken: 3.078 seconds
INFO  : Concurrency mode is disabled, not creating a lock manager
INFO  : Executing command(queryId=hadoop_20240612155511_de96a975-0b0b-4766-8b7e-d9ce68587494): select * from test_table
INFO  : Completed executing command(queryId=hadoop_20240612155511_de96a975-0b0b-4766-8b7e-d9ce68587494); Time taken: 0.006 seconds
INFO  : OK
INFO  : Concurrency mode is disabled, not creating a lock manager
+----------------+------------------+
| test_table.id  | test_table.name  |
+----------------+------------------+
| 1              | Alice            |
| 2              | Bob              |
+----------------+------------------+
2 rows selected (3.869 seconds)
```



# Cron定时调度hive脚本

使用 `cron` 来定时调度 Hive SQL 脚本是一个常见的方式。下面是一个完整的步骤，展示如何编写和配置脚本，以定时运行 Hive SQL 脚本。

## 1. 编写 Hive SQL 脚本

首先，创建一个 Hive SQL 脚本，例如 `query.hql`：

```sql

CREATE TABLE IF NOT EXISTS test.dwd_bagl_patientvisit_mi (
  FID BIGINT,
  FPRN STRING,
  FTIMES INT,
  FICDVERSION TINYINT,
  FZYID STRING,
  FAGE STRING,
  FNAME STRING,
  FSEXBH STRING,
  FSEX STRING,
  FBIRTHDAY TIMESTAMP,
  fcydate TIMESTAMP
)
PARTITIONED BY (year STRING, month STRING)
STORED AS ORC
LOCATION '/user/hive/warehouse/test.db/test_hivesql';

SET hive.exec.dynamic.partition=true;
SET hive.exec.dynamic.partition.mode=nonstrict;
INSERT OVERWRITE TABLE test.dwd_bagl_patientvisit_mi PARTITION(year, month)
SELECT 
  FID,
  FPRN,
  FTIMES,
  FICDVERSION,
  FZYID,
  FAGE,
  FNAME,
  FSEXBH,
  FSEX,
  FBIRTHDAY,
  fcydate,
  year(fcydate) AS year,
  month(fcydate) AS month
FROM test.ods_batj_patientvisit_mi
WHERE fcydate >= '2024-01-01' AND fcydate <= '2024-05-31';
```

将该脚本保存到某个目录，例如 `/path/to/query.hql`。

## 2. 编写 Shell 脚本

创建一个 Shell 脚本，例如 `run_hive_query.sh`，用来运行 Hive SQL 脚本：

```bash
#!/bin/bash

# 定义 Hive 脚本路径
HQL_SCRIPT="/data/chenli/hive/dwd_bagl_patientvisit_mi_test.hql"
LOG_DIR="/data/chenli/cron/logs"
LOG_FILE="${LOG_DIR}/hive_query_$(date +\%Y\%m\%d\%H\%M\%S).log"

# 运行 Hive 脚本
beeline -u 'jdbc:hive2://localhost:10000' -n hadoop -p hadoop -f "$HQL_SCRIPT" > "$LOG_FILE" 2>&1

# 检查执行结果
if [ $? -ne 0 ]; then
  echo "Hive query failed" | mail -s "Hive Query Failed" ****@qq.com
else
  echo "Hive query succeeded" | mail -s "Hive Query Succeeded" ****@qq.com
fi
```

将该脚本保存到某个目录，例如 `/path/to/run_hive_query.sh`。

如果有多个hive任务，可以按照以下方式

```shell
#!/bin/bash

# 定义 Hive 脚本路径
HQL_SCRIPT1="/path/to/query1.hql"
HQL_SCRIPT2="/path/to/query2.hql"

# 定义日志路径
LOG_DIR="/path/to/logs"

# 运行第一个 Hive 脚本
beeline -u 'jdbc:hive2://your-hive-server:10000/default' -n your_username -p your_password -f "$HQL_SCRIPT1" > "$LOG_DIR/hive_query1_$(date +\%Y\%m\%d\%H\%M\%S).log" 2>&1

# 检查第一个脚本的执行结果
if [ $? -ne 0 ]; then
  echo "Hive query1 failed" | mail -s "Hive Query1 Failed" your_email@example.com
  exit 1
fi

# 运行第二个 Hive 脚本
beeline -u 'jdbc:hive2://your-hive-server:10000/default' -n your_username -p your_password -f "$HQL_SCRIPT2" > "$LOG_DIR/hive_query2_$(date +\%Y\%m\%d\%H\%M\%S).log" 2>&1

# 检查第二个脚本的执行结果
if [ $? -ne 0 ]; then
  echo "Hive query2 failed" | mail -s "Hive Query2 Failed" your_email@example.com
  exit 1
fi

```



## 3. 确保 Shell 脚本具有执行权限

给 Shell 脚本添加执行权限：

```bash
chmod +x /path/to/run_hive_query.sh
```

## 4. 配置 Crontab 定时任务

编辑 Crontab 文件以配置定时任务：

```bash
crontab -e
```

添加以下行以每天定时运行 Hive SQL 脚本。例如，配置每天凌晨 1 点运行脚本：

```bash
0 1 * * * /path/to/run_hive_query.sh
```

## 5. 检查和验证 Crontab 配置

保存并退出编辑器后，验证 Crontab 配置是否生效：

```bash
crontab -l
```

## 6. 监控和日志管理

确保 Shell 脚本将日志输出重定向到指定的日志文件夹，以便后续检查：

```bash
beeline -u 'jdbc:hive2://your-hive-server:10000/default' -n your_username -p your_password -f "$HQL_SCRIPT" > /path/to/logs/hive_query_$(date +\%Y\%m\%d\%H\%M\%S).log 2>&1
```

## 7. 脚本错误通知

为了确保在脚本执行失败时能收到通知，使用邮件发送错误信息：

```bash
if [ $? -ne 0 ]; then
  echo "Hive query failed" | mail -s "Hive Query Failed" your_email@example.com
fi
```



# 问题总结

## 1.Permission denied: user=dr.who, access=WRITE, inode="/":hadoop:supergroup:drwxr-xr-x

当前用户权限不足，所以无法操作/目录

解决方案：给相应的目录赋予权限

```shell
hdfs dfs -chmod -R 777 /    --直接赋予根目录的权限
hdfs dfs -chmod -R 777 /test --赋予对应目录的权限
```

[解决方案](https://blog.csdn.net/weixin_42656458/article/details/113176108)



## 2.错误: 找不到或无法加载主类 org.apache.hadoop.mapreduce.v2.app.MRAppMaster

说明yarn没有正确配置

需要添加以下配置

```
<property>
    <name>yarn.application.classpath</name>
<value>$HADOOP_HOME/etc/hadoop:$HADOOP_HOME//share/hadoop/common/lib/*:$HADOOP_HOME//share/hadoop/common/*:$HADOOP_HOME//share/hadoop/hdfs:$HADOOP_HOME//share/hadoop/hdfs/lib/*:$HADOOP_HOME//share/hadoop/hdfs/*:$HADOOP_HOME//share/hadoop/mapreduce/lib/*:$HADOOP_HOME//share/hadoop/mapreduce/*:$HADOOP_HOME//share/hadoop/yarn:$HADOOP_HOME//share/hadoop/yarn/lib/*:$HADOOP_HOME//share/hadoop/yarn/*:/data/u01/app/hive/apache-hive-3.1.3/lib/*</value>
  </property>

```

## 3.配置Map任务时未能找到`org.apache.hive.hcatalog.data.JsonSerDe`类

配置Map任务时未能找到`org.apache.hive.hcatalog.data.JsonSerDe`类

第一种解决方案：

执行Hive时，手动添加jar包

```
ADD JAR $HIVE_HOME/lib/hive-hcatalog-core-3.1.3.jar;
```

第二种解决方案：

配置hive-site.xml

```
<property>
  <name>hive.aux.jars.path</name>
  <value>/user/hive/lib/hcatalog-core.jar</value>
</property>

```

配置yarn-site.xml

```
把hive的jar包路径添加到yarn-site.xml的classpath中
/data/u01/app/hive/apache-hive-3.1.3/lib/*


<property>
    <name>yarn.application.classpath</name>
<value>$HADOOP_HOME/etc/hadoop:$HADOOP_HOME//share/hadoop/common/lib/*:$HADOOP_HOME//share/hadoop/common/*:$HADOOP_HOME//share/hadoop/hdfs:$HADOOP_HOME//share/hadoop/hdfs/lib/*:$HADOOP_HOME//share/hadoop/hdfs/*:$HADOOP_HOME//share/hadoop/mapreduce/lib/*:$HADOOP_HOME//share/hadoop/mapreduce/*:$HADOOP_HOME//share/hadoop/yarn:$HADOOP_HOME//share/hadoop/yarn/lib/*:$HADOOP_HOME//share/hadoop/yarn/*:/data/u01/app/hive/apache-hive-3.1.3/lib/*</value>
  </property>
```

