# 数据仓库

## 数据仓库基础概念

**金科玉律**

1、在每个代理键为主键的表中，尤其维度表，必定有自然键作为可选键。绝对不允许仅仅存在一个代理键而没有自然键的现象

2、代理键绝不可以对用户可见，通常用于join，而不用where的搜索条件。此外代理键的命名规则要非常明确，比如xxxxx_SK



### NULL

**隐患**

1. 数学运算：任何数字与null值做数学运算都为null
2. where子句：搞清楚null含义，小心"<>"以及“全选”
3. join：null与null join没有结果
4. 聚合函数：若null设为0，AVG、MIN、MAX、COUNT均受影响
5. 子查询：当存在Null时，使用not in需要特别注意



### 规范化

规范化的目的：减少冗余，同一含义的数据只存一份



每个非键值属性必须依赖于键（1NF），依赖整个键而不是键的一部分（2NF），并且不依赖于其他非键值属性（3NF）



规范化之前：

1、列出实体：名词

2、勾勒关系：动词

3、尽量消除多对多关系

4、列出所有属性



#### 第一范式

原子性，列不可再分，没有重复的列，也没有重复的行



#### 第二范式

非主键属性依赖于整个键，而不是其中一部分



1、首先满足第一范式

2、如果非主键属性只依赖于主键的一部分，则需要移除创建新表



#### 第三范式

非主键属性只依赖于键，不能依赖于其他非主键属性



1、首先满足第二范式

2、如果非主键属性还依赖于其他非主属性，则需要移除创建新表



### 命名规范

1、Table Space

表空间分类 _ 数据分类 _ 数据用途 _ 8K01



2、Buffer Pool

BP_ 用途 _ 8k01



3、索引

IDX _ col name _ 索引类型



4、key

主键：PK_ col name

外键：FK _ col name _ 类型



5、约束

CK _ col name _ 类型



6、job

job_ 



7、Sequence

SEQ_ 



8、存储过程

SP _ 



### 元数据

元数据是用于描述数据的信息



### 星型模型、雪花模型

#### 事实表和维度表的关系

- **事实表**：存储的是业务事件的度量值，通常是数值型的数据，例如销量、金额、次数等。
- **维度表**：存储描述性的属性，用于提供查询上下文，例如时间、地理位置、产品类别等。

维度表是不划分数据域的，只划分业务过程。



#### 星型模型

**定义**：星型模型是一种数据仓库模式，其中一个或多个维度表直接与中央事实表相连，形成星形结构。这种模式简洁、易于理解和查询优化。

**特点**：

- 中心是事实表，周围是维度表
- 维度表和事实表之间的关系是直接的。

**示例**

假设我们要存储和分析医院手术数据，星型模型如下：

事实表

手术并发症事实表

```sql
CREATE TABLE fact_surgery_complications (
    visit_id STRING,
    patient_id STRING,
    surgery_code STRING,
    doctor_id STRING,
    department_id STRING,
    complication_code STRING,
    date_key DATE,
    complication_count INT,
    PRIMARY KEY (visit_id, complication_code)
);
```

维度表

时间维度

```sql
CREATE TABLE dim_time (
    date_key DATE PRIMARY KEY,
    year INT,
    quarter INT,
    month INT,
    day INT,
    week INT,
    weekday STRING,
    is_holiday BOOLEAN
);
```

患者维度表

```sql
CREATE TABLE dim_patient (
    patient_id STRING PRIMARY KEY,
    name STRING,
    gender STRING,
    birth_date DATE,
    age INT,
    address STRING,
    city STRING,
    state STRING,
    zip_code STRING
);
```

手术维度表

```sql
CREATE TABLE dim_surgery (
    surgery_code STRING PRIMARY KEY,
    surgery_name STRING,
    surgery_type STRING,
    surgery_duration INT
);

```

医生维度表

```sql
CREATE TABLE dim_doctor (
    doctor_id STRING PRIMARY KEY,
    name STRING,
    specialty STRING,
    department_id STRING,
    experience_years INT
);
```

科室维度表

```sql
CREATE TABLE dim_department (
    department_id STRING PRIMARY KEY,
    department_name STRING,
    location STRING
);
```

并发症维度

```sql
CREATE TABLE dim_complication (
    complication_code STRING PRIMARY KEY,
    complication_type STRING,
    description STRING
);
```

#### 雪花模型

**定义**：雪花模型是一种数据仓库模式，其中维度表被进一步规范化，将数据拆分成更小的子表，形成类似雪花的结构。

**特点**：

- 维度表是规范化的，有多个子表。
- 提供了数据的更高规范化和减少冗余。

**示例**

维表和子表

手术维度表

```sql
CREATE TABLE dim_surgery (
    surgery_code STRING PRIMARY KEY,
    surgery_name STRING,
    surgery_type_id STRING
);
```

手术类型表(子表)

```sql
CREATE TABLE dim_surgery_type (
    surgery_type_id STRING PRIMARY KEY,
    surgery_type_name STRING
);
```

医生维度表

```sql
CREATE TABLE dim_doctor (
    doctor_id STRING PRIMARY KEY,
    name STRING,
    specialty_id STRING,
    department_id STRING,
    experience_years INT
);
```

医生专科表

```sql
CREATE TABLE dim_specialty (
    specialty_id STRING PRIMARY KEY,
    specialty_name STRING
);
```

#### 总结

星型模型适用于查询简单且性能要求高的场景，雪花模型适用于数据冗余较多且需要高度规范化的场景。

**星型模型**和**雪花模型**最常用于DWS层，因为这层主要用于数据的汇总和多维度分析。通过维度表和事实表的设计，可以灵活地进行各种数据分析。



### 多维度分析

#### 多维度分析的基础

**维度**：描述业务上下文的属性，比如时间、地点、产品等。 **度量**：可以量化的业务数据，比如销售额、数量、利润等。

#### 多维度分析的核心概念

1. **维度表**：存储描述性信息，用于提供分析上下文。例如，时间维度表存储年月日信息，地点维度表存储地理信息等。
2. **事实表**：存储度量数据，并与维度表通过外键关联。例如，销售事实表存储每次销售的金额、数量等。

#### 多维度分析示例

1.**按时间和科室分析手术并发症率**

查询某一时间段内不同科室的手术并发症率：

```sql
SELECT
    t.year,
    t.month,
    d.department_name,
    SUM(f.complication_count) AS total_complications,
    COUNT(DISTINCT f.visit_id) AS total_surgeries,
    (SUM(f.complication_count) * 1.0 / COUNT(DISTINCT f.visit_id)) AS complication_rate
FROM
    fact_surgery_complications f
JOIN
    dim_time t ON f.date_key = t.date_key
JOIN
    dim_department d ON f.department_id = d.department_id
GROUP BY
    t.year, t.month, d.department_name
ORDER BY
    t.year, t.month, d.department_name;

```

2.**按医生和手术类型分析并发症**

查询不同医生在不同手术类型中的并发症发生情况：

```sql
SELECT
    d.name AS doctor_name,
    s.surgery_type,
    SUM(f.complication_count) AS total_complications,
    COUNT(DISTINCT f.visit_id) AS total_surgeries,
    (SUM(f.complication_count) * 1.0 / COUNT(DISTINCT f.visit_id)) AS complication_rate
FROM
    fact_surgery_complications f
JOIN
    dim_doctor d ON f.doctor_id = d.doctor_id
JOIN
    dim_surgery s ON f.surgery_code = s.surgery_code
GROUP BY
    d.name, s.surgery_type
ORDER BY
    d.name, s.surgery_type;

```

3.**按并发症类型和时间分析**

查询不同时间段内各类并发症的发生情况：

```sql
SELECT
    t.year,
    t.month,
    c.complication_type,
    SUM(f.complication_count) AS total_complications
FROM
    fact_surgery_complications f
JOIN
    dim_time t ON f.date_key = t.date_key
JOIN
    dim_complication c ON f.complication_code = c.complication_code
GROUP BY
    t.year, t.month, c.complication_type
ORDER BY
    t.year, t.month, c.complication_type;

```

#### 总结

- **多维度分析**通过维度表提供的上下文信息，对事实表中的度量数据进行聚合、对比和分析。
- **维度表**为数据提供描述性信息，帮助在不同维度上进行细化分析。
- **事实表**存储具体的业务事件数据，是度量数据的主要来源。



### 数据域

数据仓库模型设计除横向的分层外，通常也需要根据业务情况进行纵向划分数据域划分数据域的意义是便于数据的管理和应用。
通常可以根据业务过程或者部门进行划分，本项目根据业务过程进行划分，需要注意的是一个业务过程只能属于一个数据域。

开发过程中更好地去部署，比如如果只按照层来去划分规划部署人员的话，ODS、DIM、DWD、DWS、ADS五层，层与层之间是有一个相互依赖关系的，这样就会造成负责ADS层表格的人员都没办法直接的上手和开发，他要等到其他层完成之后才进行开发，人员安排是非常差的。

比较好的方式是每个人负责一个业务线，一个人从ODS到ADS一条业务线全部做完，这样就显得更流畅一些。

**示例**

| 数据域 | 业务过程                                   |
| ------ | ------------------------------------------ |
| 交易域 | 加购物车、下单、支付、确认收货、退单、退款 |
| 流量域 | 页面浏览、曝光                             |
| 用户域 | 注册、登录                                 |
| 互动域 | 收藏、评价                                 |
| 工具域 | 优惠券领取、优惠券使用                     |



### 拉链表

**拉链表目的**

拉链表的目的是为了记录维度数据的历史变化。每当维度数据（例如客户地址、产品价格等）发生变化时，不是直接修改现有记录，而是通过结束旧的记录，插入新的记录来保存历史信息。这种做法可以让我们查询任何时间点的数据状态，确保数据的追溯性。



**拉链表的结构**

一个拉链表通常有以下几个关键字段：

1. **主键**：例如 `customer_id`
2. **有效起始日期（start_date）**：记录该条记录的生效时间
3. **有效结束日期（end_date）**：记录该条记录的失效时间
4. **当前标识（current_flag）**：指示该记录是否为当前有效记录



**示例**

假设我们有一个客户维度表，用来记录客户信息，包括客户ID、姓名和地址。初始状态如下：

```sql
CREATE TABLE dim_customer (
    customer_id STRING,
    customer_name STRING,
    address STRING,
    start_date DATE,
    end_date DATE,
    current_flag CHAR(1),
    PRIMARY KEY (customer_id, effective_date)
);

INSERT INTO dim_customer (customer_id, customer_name, address, start_date, end_date, current_flag)
VALUES ('C001', 'John Doe', '123 Main St', '2024-01-01', '9999-12-31', 'Y');
```

假设在2024年5月29日，John Doe的地址变成了“456 Elm St”。为了记录这个变化，我们需要进行以下操作：

1. 结束旧记录

   将现有的记录（“123 Main St”）的`expiry_date`更新为新记录的`effective_date`前一天，即2024年5月28日，并将`current_flag`更新为‘N’。这样做的目的是明确旧地址在2024年5月28日失效，从而使得历史数据可追溯。

   ```sql
   UPDATE dim_customer
   SET end_date = '2024-05-28', current_flag = 'N'
   WHERE customer_id = 'C001' AND current_flag = 'Y';
   ```

2. 插入新纪录

   插入新的地址记录，并将新的记录标记为当前有效记录（`current_flag`为‘Y’）。

   ```sql
   INSERT INTO dim_customer (customer_id, customer_name, address, start_date, end_date, current_flag)
   VALUES ('C001', 'John Doe', '456 Elm St', '2024-05-29', '9999-12-31', 'Y');
   ```

**查询历史数据**

通过上述方法，拉链表能够记录客户地址在不同时间点的变化。我们可以通过`effective_date`和`expiry_date`字段来查询客户在某个时间点的地址。例如，查询2024年3月1日的地址：

```sql
SELECT customer_id, customer_name, address
FROM dim_customer
WHERE customer_id = 'C001' AND '2024-03-01' BETWEEN start_date AND end_date;
```



## 项目

做项目前的10个基本问题：

1. 规模。大中小
2. 成熟程度。低中高
3. 文档是否完备。完整、不完整、缺失
4. 是否需要特殊技能的人员。是、否
5. 是否需要与第三方合作。是、否
6. 架构的复杂性。简单、中等、复杂
7. 是否有成熟的管理模式。是、否
8. 变化频率。低中高
9. 系统关键程度。低中高
10. 是否有产品支持。是否



## 数据仓库架构图

### 整体架构图

![整体架构](D:\github\MyKnowledgeRepository\img\picture\整体架构.png)

### 技术架构图

![技术架构图](D:\github\MyKnowledgeRepository\img\picture\技术架构图.png)

### 应用架构

![应用架构图](D:\github\MyKnowledgeRepository\img\picture\应用架构.png)

### 数据架构

![数据架构图](D:\github\MyKnowledgeRepository\img\picture\数据架构.png)



**DW层**

数据仓库是一个面向主题的、集成的、相对稳定的、反映历史变化的数据集合，用于支持管理决策。

数据仓库就是多维模型模式下的数据集市的聚合



DW（数据仓库） & DM（数据集市）

数据集市是为了特定的应用目的或应用范围，而从数据仓库独立出来的一部分数据，也可以称为部门数据或主题数据

![DW & DM](D:\github\MyKnowledgeRepository\img\picture\DW和DM对比.png)



## 数据仓库建模

数据仓库建模的过程是先规范化，再逆规范化

### 逻辑模型

**日期设计**

![逻辑模型-日期](D:\github\MyKnowledgeRepository\img\picture\逻辑模型-日期.png)



**拉链表**

拉链表反应历史数据的

拉链表的实现是通过时间戳来实现的 

![拉链表](D:\github\MyKnowledgeRepository\img\picture\拉链表.png)



### 数据建模流程

1.业务调研：收集分析业务需求

2.业务域划分：分析业务和需求，将数据进行维度划分

3.明确统计指标：明确原子指标和派生指标

4.数据规范定义：构建明确的原子指标、派生指标和维度指标

5.数仓模型设计：DIM、DWD、DWS

6.代码开发。



## 实时数仓

### 传统数仓解决不了什么问题？

简单总结，就是时效性。比如用户画像需要实时特征提取、活动实时的看板、广告投放效果实时OLAP分析以及机器学习在线训练等



### 离线数仓 VS 实时数仓

![](D:\github\MyKnowledgeRepository\img\DW_img\离线数仓VS实时数仓.png)



### 数仓分层

| 层级 | 英文名                 | 中文名     | 定义                                             |
| ---- | ---------------------- | ---------- | ------------------------------------------------ |
| APP  | application            | 应用数据层 | 提供一些差异的数据服务，实现报表、自助提数等     |
| DM   | data market            | 数据集市层 | 加工多维度冗余的大宽表                           |
| DWS  | DW summary             | 汇总数据层 | 沉淀派生指标、同一计算口径、避免重复计算，可复用 |
| DWB  | DW base                | 基础数据层 | 面向主题、轻度汇总                               |
| DWD  | DW detail              | 明细数据层 | 数据的清洗、整合、分类等                         |
| DIM  | dimension              | 维度层     | 根据业务构建相应的维表                           |
| ODS  | operational data store | 操作数据层 | 直接获得数据                                     |



### 实时数仓

**ODS层**

实时数仓ODS层，本质上是把生产系统的原始数据导入MQ，原则上不做任何清洗操作

命名：ods _ {数据源存储名} _ {库名} _ {表名}



**DWD层**

dwd层采用**维度建模**理论，针对业务内容梳理业务实体的维表信息和事实表信息，设计dwd明细宽表模型。

根据设计好的模型对ods层的数据进行**数据清洗**，定义和整合。整合主要包括**多流的join**和维度扩充。

建设能表达该**业务主题**下的**多维明细宽表流**。

命名：dwd _ {主题名} _ {业务描述}

建模：梳理业务过程，设计能涵盖该**业务过程**的逻辑模型



**DWS层**

主要在dwd层的基础上针对**业务实体**跨业务主题建设**汇总指标**，设计汇总指标模型

命名：dws _ {业务实体名} _ {指标描述} _ {指标时间粒度}

建模：梳理该**实体**涉及的所有业务主题。比如直播，一场直播数据会涉及到流量主题/交易主题/电商主题等多个业务主题，需要一套dws模型涵盖实体各业务主题下的指标。



技术路线：ODS(kafka) -> DWD/DWS(kafka) -> Dim(kv、mysql、hbase) -> ADS(clickhouse、ES、Redis)



### Lambda VS Kappa 架构存在的问题

**Lambda架构**

- 同时维护实时离线两套计算模型
- 用户同时维护两套代码
- 两套数据链路，造成数据不一致

**Kappa架构**

- 消息队列回溯能力不及离线
- 消息队列无法直接提供数据查询和分享能力
- 全链路依赖消息队列，数据时序性可能造成结果错误

![](D:\github\MyKnowledgeRepository\img\DW_img\Lambda VS Kappa.png)



### Flink SQL

Flink SQL(流式SQL)是一套API，Flink会将SQL解析、优化并最终翻译成标准的Flink作业，本质上跟直接用DataStream API直接写Flink作业没有根本区别。

Flink SQL 最终会翻译成一个个的物理执行算子，上下游连接的算子之间会有数据的传输。



**Streaming SQL过程**

Streaming SQL会把Stream转化成一个动态的表，然后在这个动态的表上执行Streaming SQL，结果任然是一个动态表，而且这个动态表还可以转换为Stream

![](D:\github\MyKnowledgeRepository\img\DW_img\Streaming SQL.png)



### Hudi

Hudi是新一代的“流式数据湖平台”，为数据湖提供表的功能。





## 数仓面试题

### 数据分层

数据分层的主要原因是在管理数据的时候，对数据有一个清晰的掌控。

每个企业根据自己的业务分成不同的层次，但最基础的分层思想是分为三层：数据运营层(ODS层)、数据仓库层(DW)、数据应用层(ADS)

京东数仓分层：BDM -> FDM -> GDM -> ADM

**ODS层**

保持数据原貌不做任何修改，起到备份数据的作用。后续数据仓库加工的来源

**DW层**

DW数据分层为DWD、DWB、DWS

DWD:data warehouse details数据细节层，是业务层与数据仓库的隔离层，主要是对ODS数据层做一些数据清洗和规范化操作。

DWB:data warehouse base数据基础层，存储的是客观数据，一般作为中间层，里面有很多维度的数据层。

DWS:data warehouse service数据服务层，基于DWB的数据做聚合，用于后续的业务应用

**ADS层**

该层主要是提供数据产品和数据分析使用的数据。报表数据一般存在这里。



# 数仓建模

1.为什么要数仓建模？

数据爆发式的增长，如何有序、有结构地分类组织和存储是我们面临的一个挑战。



2.表和数据模型有什么区别？

数据模型就是数据组织和存储方法，强调的是从业务、数据存储和使用角度合理存储数据。

表就是数据存储和使用。比如给你画一个圆形，那么它代表是圆，但如果你赋予它一个意义，比如篮球，那么它代表就是篮球。

表只是物理载体，业务赋予其意义。



3.ER建模和维度建模

ER建模要符合三范式建模理论，数据冗余比较少。

维度建模最大的区别就是他不会被冗余的数据所约束住，基于事实和维度进行建模。



4.OneData体系

指标定义体系、模型设计方法体系、配套工具



5.大数据建设方法论的核心？（或者如何快速上手工作？）

从业务架构设计到模型设计，从数据研发到数据服务，做到数据可管理、可追溯、可规避重复建设。

我们未来的发展方向是以数据服务为核心，比如数据质量和数据治理提升我们数据服务准确度，数据产品提升我们数据可视化服务的体感。



6.数仓体系架构

![](D:\github\MyKnowledgeRepository\img\DW_img\数仓体系架构.png)



7.事实表分几种？

根据分层划分了明细层事实表（最原始粒度的明细数据）和汇总层事实表。明细事实表又分为三种



8.主题域如何划分？

是根据业务过程去分的。用户、渠道、营销、流量、交易、财务、商品



9.原子指标与派生指标

派生指标唯一归属于一个原子指标，继承原子指标的主题域，与修饰词的主题域无关。

派生指标 = 原子指标 + 时间周期修饰词 + 其他修饰词



10.如何区分数值型属性和事实？
如果通常用于查询约束条件或分组统计，则是作为维度属性。（用于where过滤条件的，group by分组的）
如果通过参与度量的计算（比如sum()avg()等等），则是作为事实。



11.事实表

事实表包含引用的维度和业务过程有过的度量。

事实表中一条记录所表达的业务细节程度被称为粒度，有两种方式表述：一种是维度属性组合所表示的细节程度，另一种是所表示的具体业务含义。

相对于维表，事实表要细长的多，行的增加速度也比维表快。

维度属性也可以存储到事实表中，这种存储到事实表中的维度列被称为“维度退化”。维度退化也可以进行事实表的过来查询，实现聚合操作等。

事实表有三种类型：事务事实表、周期快照事实表和累计快照事实表。

事务事实表用来描述业务过程，跟踪空间或时间上某点的度量事件，保存的是最原子的数据。

周期快照事实表以具有规律性的、可预见的时间间隔记录事实，如每天、每周、每月、每年等。

累计快照事实表用来表述过程开始和结束之间的关键步骤事件，覆盖过程的整个生命周期，通常有多个日期字段记录关键时间点，当过程随着生命周期不断变化时，记录也会随着过程的变化而被修改。



# SparK

## Spark Web Ui

Exchange节点 ： Shuffle Map阶段。相当于实现数据并行化的算子
HashAggregate预聚合：数据算子下推的一种，直接在读取数据本地进行预聚合，功能上相当于上次讲的MapReduce中的combine操作，提前在map端进行局部聚合来减少reduce端数据。这个相当于是spark sql的一个优化。但并不是所有的聚合函数都可以进行预聚合的，比如说avg()，求平均数，不能说提前先求个平均数，那就有问题了。这里的count是可以的。

spark.driver.memory=12G
spark.driver.cores=1
spark.executor.memory=8G
spark.executor.cores=4



## 数据倾斜

数据倾斜处理：分布式任务的优化就是合理的分配数据到各个节点上进行处理。但实际业务中数据很难均匀分布，比如热点用户、视频。那么数据倾斜就会产生在shuffle中：Aggregation和Join。其中Aggregation有Partial机制，问题不是很突出。在Join中，某些key数据量远大于其他时，处理这些key的任务就会非常慢，甚至挂掉。



业务层面解决思路：

1. 过滤无关数据：实际业务中大量数据倾斜都是由业务无关的数据导致。比如脏数据、null数据。排查后过滤即可。

2. 小表广播：使用map join 也就是Broadcast Join的方式避免shuffle。

3. 倾斜数据分离：将有数据倾斜表T先分为t1和t2，t1没有倾斜数据，t2只包含倾斜数据。分别join，在union。

   ```sql
        select * from (
            select * from t1,myT where t1.key = myT.key
            union all
            select /*+BROADCAST(t2)*/ * from t2,myT where t2.key = myT.key
        )
   ```

4. 数据打散：思路为分散倾斜数据。例如：将A、B两表按id 进行Join，可以先将大表A中id加后缀（id0，id1，id2），起打散作用。小表B中每条数据都复制多份。这样就可以起到数据均匀处理的效果。

   ```sql
   表A：
   select id,value,concat(id,(rand() * 1000)%3) as id_new from A
   表B：
   select id,value,concat(id,suuffix) as id_new 
   from (
       select id,value,suffix from B
       Lateral view explode(array(0,1,2)) n as suffix
   )
   ```

   

数据倾斜会在哪一个环节出现？为什么？
数据倾斜会在shuffle阶段出现，因为涉及到了数据打散，如果某个值的数据异常多，则会导致这个值全部分布在一个partition中，造成数据倾斜。在sql中join和group by会产生shuffle操作，group by一般会有预处理步骤，不用太关注；join操作是发生数据倾斜的最主要场景。

shuffle过程会消耗哪些资源？哪些会成为瓶颈？
内存、cpu、网络io、磁盘io。shuffle中涉及到了数据的shuffle write、shuffle read，数据的序列化，网络传输。在我们可控制的内存、cpu资源来看，最主要的瓶颈是shuffle read阶段会因为数据量的过大而导致内存溢出，因此需要合理的调整每个partition的数据量并均匀的分散数据。



为什么要调节并行度？
  - 并行度如果太小，每个reducer处理的数据量多，task不停的溢写会造成大量的磁盘io，导致task执行时间过长，如果内存比较小+当时的物理机不是很健康(很常见)的情况，轻则gc时间过长，重则直接任务失败。
  - 并行度如果太大，每个task处理的数据量小，driver的压力会很大（调度task），并且task多，shuffle的时候map阶段(shuffle write)写的文件也会变多，reduce段去拉取数据的时候会读取大量的小文件。
 需要注意最大并行度的设置，不要设为2的幂次方（收起程序员的强迫症），这是由于Hash分区函数的特性导致

 并行度越大越好吗？为什么？
 并不是。在每个task处理的数据量过多时，可以适当增加并行度来减少每个task处理的数据量，以此增加速度。但当task处理的数据量非常小时，可以适当的减小并行度来减少task个数，因为driver在生成、分配、监视task时需要消耗时间，executor在切换处理task时也需要消耗时间。这些额外的消耗积少成多，增加了任务总时长。



 输出小文件合并
Spark输出文件的数量由最后一个stage的并行度来决定。

合并小文件的目的：
1. 为了下游任务使用时task数量变少，虽然有相关参数调节，但从根本上解决最好。
2. hdfs是设计为存储大块儿数据使用的，如果分割的文件太小，则会导致文件数过多，那么管理文件元数据的namenode就会有很大压力。



一个sql语句是如何处理数据的
![](D:\github\MyKnowledgeRepository\img\DW_img\sql语句执行.png)

1. 逻辑计划：
  1. 未解析的逻辑算子树：仅有数据结构，不包含数据信息。
  2. 解析的逻辑算子树：节点中绑定各种信息。
  3. 优化后的逻辑算子树：应用各种优化规则对一些抵消的逻辑计划进行转换。
2. 物理计划：
  1. 根据逻辑算子树生成物理算子树的列表（可能1对多）
  2. 从列表中按一定的策略选取最优的物理算子树。
  3. 对选取的物理算子树进行提交前的准备工作：确保分区操作正确、物理算子树节点重用、执行代码生成等。

![](D:\github\MyKnowledgeRepository\img\DW_img\sql语句执行2.png)
以上步骤都在driver端进行，不涉及分布式计算





## Spark Join

链接 ： https://zhuanlan.zhihu.com/p/88623042

总体上来说，Join的基本实现流程如下图所示，Spark将参与Join的两张表抽象为流式表(StreamTable)和查找表(BuildTable)，通常系统会默认设置为StreamTable大表，BuildTable为小表。流式表的迭代器为streamItr，查找表迭代器为BuidIter。Join操作就是遍历streamIter中每条记录，然后再buildIter中查找相匹配的记录。
spark join 图片

1.1 BroadcastJoin机制：
对小表进行广播，避免shuffle的产生。web ui的sql图可以看到driver collect的时间，build建表压缩时间，broadcast广播时间。所以频繁有广播时，会对driver端产生较大压力。需要注意的是：在Outer类型的Join中，基表不能被广播，比如A left outer join B时，只能广播右表B。
触发场景：

- 被广播表小于参数 spark.sql.autoBroadcastJoinThreshold=20971520，默认10MB。公司改默认20MB

- 在SQL中显示添加Hint（MAPJOIN、BROADCASTJOIN或BROADCAST）

  ![](D:\github\MyKnowledgeRepository\img\DW_img\broadcast join.png)

1.2 ShuffledHashJoin机制：
步骤：
1. 对两张表分别进行shuffle重分区，将相同key的记录分到对应分区中，这一步对应Exchange节点
2. 将查找表分区构造一个HashMap，然后在流式表中一行行对应查找。

要将来自BuildTable每个分区的记录放到hash表中，那么BuildTable就不能太大，否则就存不下，默认情况下hash join的实现是关闭状态，如果要使用hash join，原生spark必须满足以下四个条件：
1. 查找表总体估计大小超过spark.sql.autoBroadcastJoinThreshold设定的值，即不满足BroadcastJoin 条件
2. 关闭优先使用SortMergeJoin开关，spark.sql.join.preferSortMergeJoin=false
3. 每个分区的平均大小不超过spark.sql.autoBroadcastJoinThreshold设定的值，查找表数据量 < 广播数据阈值 * shuffle的partition数。
4. streamIter的大小是buildIter三倍以上

ShuffledHashJoin触发条件非常苛刻，我司有相关优化策略，下面会提到。

![](D:\github\MyKnowledgeRepository\img\DW_img\ShuffledHashJoin.png)

1.3 SortMergeJoin机制：
此为spark sql的主要join方式，hash join是将一侧的数据完全加载到内存中，这对一定大小的表比较适用，但两个表都很大时，无论加载哪个表到内存都不理想。所以spark sql使用sort merge的方式。
步骤：
3. 对两张表分别进行shuffle重分区，将相同key的记录分到对应分区中并进行排序，这一步对应Exchange节点和sort节点。也就是spark 的sort merge shuffle过程。
4. 遍历流式表，对每条记录都采用顺序查找的方式从查找表中搜索，由于排序的特性，每次处理完一条记录，只需从上一次结束的位置开始继续查找。整体上来说，查找性能还是较优的。

![](D:\github\MyKnowledgeRepository\img\DW_img\MergesortJoin.png)





# Bytedance 数仓笔记



# 数仓亮点介绍

亮点分两种：

1业务价值亮点：用户增长，留存，风险拦截，防止资损，算法模型召回提升等；

2技术价值亮点：做了xx链路，xx数据服务为业务提升效率，通过数据治理降低资源消耗，每个月节省部门的包xx%，亮点在于最终带来的结果，不是说我做了xx个dwd模型，xx个指标


数仓层面，某些主题域使用很多年后，因为人员变动，开发不规范等原因，指标混乱，直接 ods 取数等状况， 重构某主题域，ads 指标沉淀 dws， 减少 ads 小烟囱开发，减少 ods 穿透率，指标口径一致性提高。业务层面，做了某需求，给业务带来业绩增长，业务部门人效提高等。



支持某某业务，提升了客户活跃度，营销成功率，实现某某业务销售额增长/保证在经济下行时的经营状况稳定。
同时通过数据治理，模型优化，减少消耗，节省了多少资源，数据效率提升了多少，跑批时间节约了多少
