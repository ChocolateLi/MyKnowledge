# 集群资源配置优化

# yarn-site.xml

```xml
<configuration>
    <!-- NodeManager的总内存和CPU核心数 -->
    <property>
        <name>yarn.nodemanager.resource.memory-mb</name>
        <value>24576</value> <!-- 每台机器的总内存：24GB -->
    </property>
    <property>
        <name>yarn.nodemanager.resource.cpu-vcores</name>
        <value>16</value> <!-- 每台机器的CPU核心数：16 -->
    </property>

    <!-- YARN调度器每个容器的内存和CPU核心分配 -->
    <property>
        <name>yarn.scheduler.minimum-allocation-mb</name>
        <value>1024</value> <!-- 单个容器最小内存：1GB -->
    </property>
    <property>
        <name>yarn.scheduler.maximum-allocation-mb</name>
        <value>8192</value> <!-- 单个容器最大内存：8GB -->
    </property>
    <property>
        <name>yarn.scheduler.minimum-allocation-vcores</name>
        <value>2</value> <!-- 单个容器最小CPU核心数：2 -->
    </property>
    <property>
        <name>yarn.scheduler.maximum-allocation-vcores</name>
        <value>4</value> <!-- 单个容器最大CPU核心数：4 -->
    </property>

    <!-- 启用LinuxContainerExecutor和CGroups支持 -->
    <property>
        <name>yarn.nodemanager.container-executor.class</name>
        <value>org.apache.hadoop.yarn.server.nodemanager.LinuxContainerExecutor</value>
    </property>
    <property>
        <name>yarn.nodemanager.linux-container-executor.cgroups.enabled</name>
        <value>true</value>
    </property>
</configuration>

```

# mapred-site.xml

```xml
<configuration>
    <!-- Mapper和Reducer的内存和CPU核心配置 -->
    <property>
        <name>mapreduce.map.memory.mb</name>
        <value>4096</value> <!-- 每个Mapper任务的内存：4GB -->
    </property>
    <property>
        <name>mapreduce.reduce.memory.mb</name>
        <value>4096</value> <!-- 每个Reducer任务的内存：4GB -->
    </property>
    <property>
        <name>mapreduce.map.cpu.vcores</name>
        <value>2</value> <!-- 每个Mapper任务使用2个核心 -->
    </property>
    <property>
        <name>mapreduce.reduce.cpu.vcores</name>
        <value>2</value> <!-- 每个Reducer任务使用2个核心 -->
    </property>
    
    <!-- Mapper和Reducer的JVM堆大小 -->
    <property>
        <name>mapreduce.map.java.opts</name>
        <value>-Xmx3072m -XX:+UseG1GC</value> <!-- Mapper的JVM堆大小：3GB -->
    </property>
    <property>
        <name>mapreduce.reduce.java.opts</name>
        <value>-Xmx3072m -XX:+UseG1GC</value> <!-- Reducer的JVM堆大小：3GB -->
    </property>
</configuration>

```

# hadoop-env.sh

```bash
# 设置Hadoop的全局内存和GC配置
export HADOOP_HEAPSIZE=4096  # Hadoop全局内存：4GB
export HADOOP_NAMENODE_OPTS="-Xmx2048m -XX:+UseG1GC"  # NameNode的堆内存：2GB
# export HADOOP_DATANODE_OPTS="-Xmx4096m -XX:+UseG1GC"  # DataNode的堆内存：4GB
export HDFS_DATANODE_OPTS="$HDFS_DATANODE_OPTS -Xmx4096m -XX:+UseG1GC"
export HADOOP_OPTS="-XX:+UseG1GC -XX:InitiatingHeapOccupancyPercent=35"  # 启用G1GC
# export HDFS_DATANODE_OPTS="$HDFS_DATANODE_OPTS -Xmx4096m -XX:+UseG1GC"


```

# yarn-env.sh

```bash
# 设置YARN的内存和垃圾回收策略
export HADOOP_HEAPSIZE=4096  # YARN的全局内存：4GB
export YARN_RESOURCEMANAGER_OPTS="-Xmx4096m -XX:+UseG1GC"  # ResourceManager内存：4GB
export YARN_NODEMANAGER_OPTS="-Xmx4096m -XX:+UseG1GC"  # NodeManager内存：4GB
export HADOOP_OPTS="-XX:+UseG1GC -XX:InitiatingHeapOccupancyPercent=35"
```

# hive-env.sh

```bash
# 设置Hive服务的内存配置
export HIVE_HEAPSIZE=4096  # HiveServer2的堆内存：4GB
export HADOOP_HEAPSIZE=4096  # Hive使用的Hadoop客户端内存：4GB
export HADOOP_OPTS="-XX:+UseG1GC -XX:InitiatingHeapOccupancyPercent=35"  # 启用G1GC
```

