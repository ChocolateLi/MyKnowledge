

# 云服务器上搭建大数据环境

## Linux命令

### 文件相关命令

find文件查找

```shell
find <指定目录><指定条件>
find ./ -name '*.txt' 查找当前目录(含子目录)以.txt文件结尾的
```

查看文件某个文件的属性

```
ls -lh 文件名
```

### 用户管理

创建用户

```shell
sudo useradd chenli
sudo passwd chenli
```

删除用户

```
userdel -r chenli 删除用户及其家目录文件
userdel chenli 删除用户，但不删除其家目录文件
```

新建用户组

```
groupadd groupname
```

将用户添加进工作组

```
usermod -G groupname username
```

用户所归属的用户组查询

```
groups 用户名
```

用户身份切换

```
su命令可以变更其他使用者的身份，需要键入使用者的密码

sudo只允许使用提升的权限运行单个命令，需要在 /etc/sudoers文件中定义
sudo提供了一个编辑该文件的命令：visudo。可以对该文件进行修改
加%代表用户组，ALL=(ALL)表示登录者的来源主机，最后的ALL表示可执行的命令。NOPASSWD代表不需要密码直接可以执行sudo，限制多条命令，一定要写绝对路径，用逗号分开，多行用‘\’，用！代表不能执行
%chenli	ALL=(ALL) NOPASSWD:ALL
%chenli ALL=(ALL) NOPASSWD:/bin/ls,/usr/bin,!/usr/bin/passwd root	

sudo -l 来查看哪些命令是可以执行或禁止的 
```

查询用户命令

```
w 用查询当前在线用户，以及每个用户正在执行的进程
who 显示当前登录的所有用户
last 显示目前与过去登入系统的用户相关信息
lastlog 显示每个用户最后的登录时间
id 查看用户id信息
```

more /etc/passwd 查看用户身份信息文件

```
里面信息展示如下：
用户名称：用户密码：用户id：用户主组id：用户说明：用户家目录：用户默认shell
```

more /etc/group 查看组身份信息

```
里面展示信息如下：
组名称：组密码：组id：组的附加成员
```





### 软件安装

#### RPM（redhat package manager）

RPM软件的安装、删除、更新只有root权限才能使用。



初始化rpm数据库

```
rpm --initdb
rpm --rebuilddb

这两个参数是极为有用的，有时rpm系统出了问题，不能安装和查询，大多是这里出了问题。
/var/lib/rpm目录下的数据库记录所有软件的升级需求，记录所有已经安装的所有软件
```

查询已经安装的软件名

```
rpm -q 软件名  == rpm -qa|grep 软件名

rpm -qa 查看系统中所有已经安装的包

rpm -qa|more 分页查看系统中所有已经安装的包
```

查询已安装软件包都安装到何处

```
rpm -ql 软件名
```

查询一个已安装软件包的信息

```
rpm -qi 软件名
```

安装和升级一个rpm包

```
rpm -vih file.rpm 这是用来安装一个新的rpm包
rpm -Uvh file.rpm 这是用来升级一个rpm包
```

删除一个rpm包（先查询后删除）

```
rpm -e 软件名
```

#### yum（yellow dot update modified）

rpm安装软件需要手动解决包之间的依赖关系，yum很好地解决了这个问题，他可以自动解决包之间的依赖关系。



查看rpm是否安装

```
rpm -qa | grep yum
```

yum配置文件，创建容器，位置在/etc/yum.repos.d，扩展名必须是.repo

```
cd /etc/yum.repos.d 
vim yum.repo 	新建一个仓库文件，名字可以随便定义，在文件写如下内容

[base] #代表容器名称，中括号一定要存在，里面的名字可随便取
name=base #说明这个容器的意义，随便写都可以
baseurl=ftp://192.168.0.6/pub/Server #192. 168. 0. 6 是你的 YUM 源地址，这个很重要。 
enabled=1 #是否启动，=0 则不启动，不启动就无法使用该源
gpgcheck=0 #是否验证. 可不要 
gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-redhat-release #验证的密钥. 可不要
```

安装软件

```
yum install
```

删除软件

```
yum remove
```

列出已经安装的软件

```
yum list install
```

### 进程管理

**进程的属性**

进程ID(PID)：唯一的数值，用来区分进程

父进程ID(PPID)

启动进程的用户ID(UID)和所归属的组(GID)

进程状态：运行R、休眠S、僵尸Z



**ps**

ps为我们提供了一次性查看进程，想要对进程时间监控应用top命令

ps aux

```
USER	表示启动进程用户
PID	表示进程标志号
%CPU 表示运行该进程占用CPU的时间与该进程总的运行时间的比例
%MEM 表示该进程占用内存和总内存的比例
VSZ	表示占用的虚拟内存大小，以KB为单位。
RSS 表示进程占用的物理内存值，以KB为单位
TTY 表示该进程建立时所对应的终端，？表示该进程不占用终端
STAT 表示进程的运行状态，包括一下几种代码：
			D	不可中断的睡眠
			R 就绪（在可运行队列中）
			S 睡眠
			T 被跟踪或停止
			Z 终止（僵尸）的进程
			W 没有足够的内存分页可分配
			< 高优先序进程
			N 低优先序进程
			L	有内存分页分配并锁在内存体内
START	为进程开始时间
TIME 执行的时间
COMMAND 对应的命名名
```

可以用｜管道和more连接起来分页查看

```
ps -aux|more 
```

把所有进程显示出来，并输出到ps001.txt文件中，然后用more来分页查看

```
ps -aux > ps001.txt
more ps001.txt
```

和grep结合，提取指定程序的进程

```
ps -aux | grep httpd
```

父进程和子进程的关系友好判断

```
pa -auxf|grep httpd
这里用到了f参数；父与子关系一目了然
```

找出内存消耗最多的前10名进程

```
ps -auxf|sort -nr -k 4|head -10
```

找出使用CPU最多的前10名进程

```
ps -auxf | sort -nr -k 3|head -10
```

Pstree 命令列出当前的进程，以及他们的树状结构

top命令显示的内容解释

```
第一行表示的项目依次为当前时间、系统启动时间、当前系统登录的用户数、平均负载
第二行显示的是Tasks:total 进程总数、running正在运行的进程数、sleeping睡眠的进程数、stop停止的进程数、zombie僵尸进程数
第三行显示的是目前cpu的使用情况，CPUS:us用户空间占用cpu百分比、sy内核空间占用cpu百分比、ni用户进程空间内改变过优先级的进程占用cpu			百分比、id空闲cpu百分比、wa等待输入输出的cpu时间百分比
第四行显示物理内存使用情况，Mem:total物理总内存量、use使用的物理内存、free空闲内存情况、buffers用作内核缓存的内存量
第五行显示交换区使用情况，Swap
第六行显示参数，下列列出解释
PID:进程标志号
USER:进程所有者的用户名
PR:进程的优先级别，值越小优先级越高
NI:进程优先级别数值 -20～20，正值优先级低，负值优先级高，零表示不会调整该进程的优先级
VIRT:进程占用的虚拟内存值
RES:进程占用的物理内存值
SHR:进程使用的共享内存值
STAT：进程的状态，S表示休眠、R表示正在运行、Z表示僵死状态、N表示该进程优先值是负数
%CPU:该进程占用的CPU使用率
%MEM:该进程占用的物理内存和总内存占比
TIME:该进程启动后占用CPU时间
COMMAND：进程启动的启动命令名称
```

内存监控

```
free -m
-m	表示MB为单位显示内存使用情况
```

### VIM编辑器

```
i:当前字符的左边插入
l:当前字符的行首插入
a:当前字符的右边插入
A:当前行尾插入
o:在当前行下面插入新行
O:在当前行上面插入新行

ctrl+f 向下翻页
ctrl+b 向上翻页

G:移动到文件最后一行
gg:移动到文件第一行

dd:删除整行
yy：复制光标所在行
p:将复制的数据在光标下一行粘贴
P:将复制的数据在光标上一行粘贴
u:撤销前一个操作

:w 保存数据
:wq 保存退出
:q! 不保存退出
:w 文件名 			相当于另存为
```

### 防火墙

如果防火墙开启，我们ping Linux服务器的IP会ping不通，所以我们要对防火墙进行设置。

systemctl是CentOS7的服务管理工具中主要的工具，它融合之前service和chkconfig的功能于一体。

查看防火墙状态

```
systemctl status firewalld

firewall-cmd --state //查看防火墙状态
```

启动防火墙

```
systemctl start firewalld
```

停止防火墙

```
systemctl disable firewalld
```

禁用防火墙

```
systemctl stop firewalld
```

开放端口 如80

```
开放端口
firewall-cmd --zone=public --add-port=80/tcp --permanent
重新载入
firewall-cmd --reload
查看端口
firewall-cmd --zone=public --query-port=80/tcp
删除端口
firewall-cmd --zone=public --remove-port=80/tcp --permanent
```





### 查看系统常用配置

查看CPU信息

```shell
cat /proc/cpuinfo
```

查看环境变量

```shell
env
```

查看实时运行程序资源占用情况

```
top

q退出
```



查看进程号

```
ps -ef|grep 特定进程

kill -9  进程号
```

查看端口

```
netstat -antp | grep 端口号
```

列出目录所占空间

```
du -sh 显示当前目录大小
du -sh / 显示/目录下的所有目录大小 
```



### linux 程序安装目录/opt目录和/usr/local目录的区别

/opt目录用来安装附加软件包，是用户级的程序目录，可以理解为D:/Software。这里可以用于放置第三方大型软件（或游戏）

/usr：系统级的目录，可以理解为C:/Windows/

/usr/local：用户级的程序目录，可以理解为C:/Progrem Files/。用户自己编译的软件默认会安装到这个目录下

自定义的脚本(scripts)放到/usr/local目录下面



### 配置环境变量

**环境变量分类**

用户级别的：~/.bashrc、~/.profile

系统级别的：/etc/bashrc、/etc/profile

**Linux加载环境变量顺序**

/etc/profile

~/.profile

~/.bashrc



#### JDK环境变量

1、vi /etc/profile

2、在profie文件末尾添加jdk路径：

​		##JAVA_HOME

​		export JAVA_HOME=/opt/module/jdk1.7.0_79

​		export PATH=$PATH:$JAVA_HOME/bin

3、source  /etc/profile



## 配置集群ssh免密码登录



1、在三台机器的/etc/hosts文件中，都配置对三台机器的ip-hostname的映射

2、首先在三台机器上配置对本机的ssh免密码登录

生成本机的公钥，过程中不断敲回车即可，ssh-keygen命令默认会将公钥放在/root/.ssh目录下

ssh-keygen -t rsa

将公钥复制为authorized_keys文件，此时使用ssh连接本机就不需要输入密码了

cd /root/.ssh

cp id_rsa.pub authorized_keys

3、接着配置三台机器互相之间的ssh免密码登录

使用ssh-copy-id -i spark 命令将本机的公钥拷贝到指定机器的authorized_keys文件中（方便好用）

ssh-copy-id -i  root@192.168.1.102



host文件：

192.168.1.115 sparkproject1
192.168.1.117 sparkproject2
192.168.1.118 sparkproject3



## Hadoop集群搭建

### hadoop安装

把文件上传到 /opt/software目录下

然后解压到 /opt/module目录下

解压命令：tar -zxvf  文件名  -C  目标路径



**将Hadoop添加到环境变量中**

1、vi /etc/profile

2、\##HADOOP_HOME

​	export HADOOP_HOME=/opt/module/hadoop-3.1.3

​	export PATH=$PATH:$HADOOP_HOME/bin

​	export PATH=$PATH:$HADOOP_HOME/sbin

3、source /etc/profile



### 集群规划

注意：NameNode和SecondaryNameNode不要安装在同一台服务器

注意：ResourceManager也很消耗内存，不要和NameNode、SecondaryNameNode配置在同一台机器上

但是我目前只有两台云服务器，所以我把NameNode和ResourceManager放在一起

|      | hadoop1                    | hadoop2                     |
| ---- | -------------------------- | --------------------------- |
| HDFS | NameNode、DataNode         | SecondaryNameNode、DataNode |
| YARN | ResourManager、NodeManager | NodeManager                 |

### 配置文件

**配置core-site.xml**

```
<property>
        <name>fs.defaultFS</name>
        <value>hdfs://hadoop1:8020</value>
</property>
<property>
        <name>hadoop.tmp.dir</name>
        <value>/opt/module/hadoop-3.1.3/data</value>
</property>
```

**配置hdfs-site.xml**

```
<configuration>
    <property>
        <name>dfs.namenode.secondary.http-address</name>
        <value>hadoop2:9868</value>
    </property>
    
    <property>
         <name>dfs.name.dir</name>
         <value>/opt/module/hadoop-3.1.3/data/namenode</value>
    </property>

    <property>
         <name>dfs.data.dir</name>
         <value>/opt/module/hadoop-3.1.3/data/datanode</value>
    </property>

    <property>
         <name>dfs.tmp.dir</name>
         <value>/opt/module/hadoop-3.1.3/data/tmp</value>
    </property>

    <property>
         <name>dfs.replication</name>
         <value>1</value>
    </property>
</configuration>
```

**配置mapred-site.xml**

```
<property>
        <name>mapreduce.framework.name</name>
        <value>yarn</value>
</property>
<!-- 历史服务器端地址 -->
<property>
    <name>mapreduce.jobhistory.address</name>
    <value>hadoop1:10020</value>
</property>

<!-- 历史服务器web端地址 -->
<property>
    <name>mapreduce.jobhistory.webapp.address</name>
    <value>hadoop1:19888</value>
</property>
```

**配置yarn-site.xml**

```
<property>
     <name>yarn.resourcemanager.hostname</name>
     <value>hadoop1</value>
</property>

<property>
     <name>yarn.nodemanager.aux-services</name>
     <value>mapreduce_shuffle</value>
</property>
```

**修改slaves(或者workers)**

```
hadoop1
hadoop2
```

### 启动hdfs集群

1、**（第一次启动才要）**格式化namenode：在hadoop1上执行以下命令：hdfs namenode -format

2、启动hdfs集群：start-dfs.sh
3、验证启动是否成功：jps、50070端口

hadoop1：namenode、datanode

hadoop2：secondarynamenode、datanode

4、hdfs dfs -put hello.txt /hello.txt



**注**：如果集群是第一次启动，需要在hadoop1节点格式化NameNode（注意格式化之前，一定要先停止上次启动的所有namenode和datanode进程，然后再删除data和log数据）



### 启动yarn集群

在配置了ResourceManager的节点（hadoop1启动YARN集群）

1、启动yarn集群：start-yarn.sh
 2、验证启动是否成功：jps、8088端口

haoop1：resourcemanager、nodemanager

hadoop2：nodemanager



### 启动历史服务器

在hadoop1启动历史服务器

```shell
mapred --daemon start historyserver
```

### 错误总结

1、hadoop-3.1.0启动hadoop集群时还有可能可能会报如下错误

```shell
[root@localhost sbin]# start-all.sh
Starting namenodes on [hadoop]
ERROR: Attempting to operate on hdfs namenode as root
ERROR: but there is no HDFS_NAMENODE_USER defined. Aborting operation.
Starting datanodes
ERROR: Attempting to operate on hdfs datanode as root
ERROR: but there is no HDFS_DATANODE_USER defined. Aborting operation.
Starting secondary namenodes [hadoop]
ERROR: Attempting to operate on hdfs secondarynamenode as root
ERROR: but there is no HDFS_SECONDARYNAMENODE_USER defined. Aborting operation.
2018-07-16 05:45:04,628 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Starting resourcemanager
ERROR: Attempting to operate on yarn resourcemanager as root
ERROR: but there is no YARN_RESOURCEMANAGER_USER defined. Aborting operation.
Starting nodemanagers
ERROR: Attempting to operate on yarn nodemanager as root
ERROR: but there is no YARN_NODEMANAGER_USER defined. Aborting operation.
```

解决办法：在 /etc/profile文件下添加以下内容

```shell
export HDFS_NAMENODE_USER=root
export HDFS_DATANODE_USER=root
export HDFS_SECONDARYNAMENODE_USER=root
export YARN_RESOURCEMANAGER_USER=root
export YARN_NODEMANAGER_USER=root
```

2、启动hadoop，报错Error JAVA_HOME is not set and could not be found

其实环境都装好了，还是报错

解决办法：在hadoop-env.sh文件中添加以下配置

```shell
export JAVA_HOME=/opt/module/jdk1.8.0_212
```

3、Hadoop集群环境——启动时报错“java.net.BindException: Cannot assign requested address

```
那么具体的解决办法就是：
1.在Master服务器上，要将自己的ip设置成内网ip，而将另一台Slave服务器的ip设置成外网ip；
2.同样的在Slave服务器上，要将自己的ip设置成内网ip，而将另一台Master服务器的ip设置成外网ip

把core-site.xml里<name>fs.defaultFS</name>的<value>里的服务器ip地址改为localhost，就没报该错了

搭建云服务器上的集群时尤其要注意这一点，不然namenode和secondarynamenode的配置文件要修改为localhost。自己主机上的要修改为localhost，其他主机可以不用。
```

4、在Hadoop3.x上执行MapReduce程序时，报出如下错误

```
Error: Could not find or load main class org.apache.hadoop.mapreduce.v2.app.MRAppMaster
 
Please check whether your etc/hadoop/mapred-site.xml contains the below configuration:
<property>
  <name>yarn.app.mapreduce.am.env</name>
  <value>HADOOP_MAPRED_HOME=${full path of your hadoop distribution directory}</value>
</property>
<property>
  <name>mapreduce.map.env</name>
  <value>HADOOP_MAPRED_HOME=${full path of your hadoop distribution directory}</value>
</property>
<property>
  <name>mapreduce.reduce.env</name>
  <value>HADOOP_MAPRED_HOME=${full path of your hadoop distribution directory}</value>
</property>
```

mapred-site.xml配上这些文件

```
 <property>
    <name>yarn.app.mapreduce.am.env</name>
    <value>HADOOP_MAPRED_HOME=$HADOOP_HOME</value>
 </property>
 <property>
    <name>mapreduce.map.env</name>
    <value>HADOOP_MAPRED_HOME=$HADOOP_HOME</value>
  </property>
  <property>
    <name>mapreduce.reduce.env</name>
    <value>HADOOP_MAPRED_HOME=$HADOOP_HOME</value>
  </property>
```

5、yarn 8088端口访问不了情况

解决办法：修改配置文件yarn-site.xml

```shell
<property>
       <name>yarn.resourcemanager.hostname</name>
       <value>localhost</value>
  </property>

  <property>
       <name>yarn.nodemanager.aux-services</name>
       <value>mapreduce_shuffle</value>
  </property>

  <property>
          <name>yarn.resourcemanager.address</name>
          <value>0.0.0.0:8032</value>
   </property>
   <property>
          <name>yarn.resourcemanager.scheduler.address</name>
          <value>0.0.0.0:8030</value>
   </property>
   <property>
          <name>yarn.resourcemanager.resource-tracker.address</name>
          <value>0.0.0.0:8031</value>
   </property>
   <property>
          <name>yarn.resourcemanager.admin.address</name>
          <value>0.0.0.0:8033</value>
   </property>
   <property>
          <name>yarn.resourcemanager.webapp.address</name>
          <value>0.0.0.0:8088</value>
  </property>
```







## 脚本文件

放在 /usr/local/bin目录下

更改文件权限 chmod 777 文件

### all-jps.sh(查看所有主机的进程)

```shell
#!/bin/bash
for((host=1; host<=2; host++)); do
                echo "================  hadoop$host JPS  ====================="
        ssh hadoop$host "jps"
done
```

### xsync(同步脚本)

如果本机或者远程计算机没有安装 rsync，可以用下面的命令安装

sudo yum install rsync



```shell
#!/bin/bash
#1 获取输入参数个数，如果没有参数，直接退出
pcount=$#
if ((pcount==0)); then
echo no args;
exit;
fi
 
#2 获取文件名称
p1=$1
fname=`basename $p1`
echo fname=$fname
 
#3 获取上级目录到绝对路径
pdir=`cd -P $(dirname $p1); pwd`
echo pdir=$pdir
 
#4 获取当前用户名称
user=`whoami`
 
#5 循环
for((host=1; host<3; host++)); do
        echo ------------------- hadoop$host --------------
        rsync -rvl $pdir/$fname $user@hadoop$host:$pdir
done
```

