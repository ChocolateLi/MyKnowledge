# 计算机网络、操作系统内容总结

## 计算机网络

### 一、基础知识

#### 1、五层网络结构

![五层网络结构](D:\github\MyKnowledgeRepository\picture\五层网络模型.png)



**应用层**

应用层的任务是为应用程序的交互提供服务的。

应用层协议定义的是应用进程间的交互和通信规则。



如：万维网协议HTTP、域名系统DNS、文件上传协议FTP、支持邮件的SMTP协议

应用层交互的数据单元称为报文



**传输层**

传输层的任务是为两台主机进程间的通信提供通用的数据传输服务的。

所谓的“通用的”并不是针对特定网络应用，而是多种应用都可以使用同一个传输层服务。



应用进程利用该服务传输应用报文。



一台主机可以同时运行多个进程。因此传输层有复用和分用的功能。

复用，指的是多个应用进程可以同时使用传输层服务。

分用，指的是传输层把收到的信息分别交互给应用层的各个进程。



两种协议

TCP - 面向连接，提供可靠传输

UDP - 提供无连接，尽最大努力交互



**网络层**

在计算机网络中进行通信的两台计算机，可能会经过很多数据链路层，经过很多通信子网。

网络层的任务就是选择合适的路由和交换节点，确保数据及时传送。



在发送数据时，网络层会把传输层的报文段或用户数据报封装成分组和包进行传送。

常用协议：IP、ARP、RARP、ICMP、IGMP



**数据链路层**

两台主机的数据传输总是在一段一段的链路上传输的，因此需要专门的数据链路协议。

两个相邻节点之间传输数据时，数据链路层会将网络层交下来的IP数据报封装成帧，在两个相邻的节点上传送帧。



常用协议：ARQ



**物理层**

物理层传输的最小单位是比特。

物理层的作用是实现相邻计算机之间比特流的传输，它尽可能屏蔽传输介质和物理设备的差异。

#### 2、面试常见协议

**ARP协议的工作原理**

网络层的ARP协议的作用是完成IP地址与物理地址的映射。

1. 每台主机都有自己的ARP缓冲区列表，记录着IP地址和MAC地址的映射关系

2. 当源主机向目标主机发送数据包时，先从ARP列表中查询目标主机的IP地址对应的MAC地址；如果有，直接将数据包发给MAC地址这个；如果没有，则发起一个广播，查询目标主机对应的MAC地址

3. 网络中的所有主机收到ARP请求后，都会查询目的IP是否和自己的IP相同；若相同，会将发起请求的IP地址和MAC地址存储在自己的ARP列表中，并向源主机发送ARP响应包，告诉对方它就是你要找的MAC地址主机。

4. 源地址主机收到ARP响应包后，会将里面的IP地址和MAC地址存在自己的ARP列表中，然后利用此信息开始传输数据。

   

**TCP的主要特点是什么**

1. TCP是面向连接的
2. TCP的连接只有有两个端点，即它是点对点的
3. TCP提供可靠交付。即TCP连接传送的数据是无差错、不丢失、不重复、并且按序达到。
4. TCP提供全双工通信。即TCP允许通信双方的应用程序在任何时候都可以发送数据。
5. 它是面向字节流的。即把应用层传下来的报文看成字节流，把字节流组成大小不等的数据块。



**UDP的主要特点是什么**

1. UDP面向无连接
2. UDP允许一对一、一对多、多对多发送信息
3. UDP是尽最大努力交付
4. UDP没有拥塞控制。即它不管网络阻不阻塞，它就是一直发数据
5. UDP是面向报文的。即应用传下来的报文不合并不拆分，只添加UDP头部。



**TCP和UDP的区别**

TCP和UDP的特点就是它们的区别



### 二、TCP/IP

#### 1、TCP三次握手、四次挥手

##### 1、TCP三次握手过程

![TCP三次握手过程](D:\github\MyKnowledgeRepository\picture\TCP三次握手.png)

- 首先，客户端和服务端都处于close状态，服务器主动监听某个端口号，处于listen状态
- 客户端会随机初始化序列号，将此序列号置于TCP首部的’序列号‘字段中，同时把SYN标志置为1，表示SYN报文。接着把第一个SYN报文发给服务端，客户端处于syn-sent状态。（该报文不包含应用层数据）
- 服务端收到客户端的SYN报文后，也随机初始化自己的序列号，将此序列号置于TCP首部的'序列号'字段中，其次把TCP首部的’确认应答号‘字段填入客户端的序列号+1，接着把SYN和ACK标志置为1，把该报文发给客户端。之后服务端处于SYN-RCVD状态。（该报文不包含应用层数据）
- 客户端收到服务端的报文后，先将ACK标志置为1，在自己的‘确认应答号’字段中填入服务端序列号+1，最后把报文发给服务端。客户端处于estab-lished状态。（该报文可以携带应用层数据）
- 服务端收到客户端应用报文后，也进入estab-lished状态。



第三次握手可以携带数据，前两次握手不可携带数据。



##### 2、TCP四次挥手过程

![TCP四次挥手过程](D:\github\MyKnowledgeRepository\picture\TCP四次挥手.png)

1. 客户端发送释放报文（即TCP首部FIN标志置为1的报文，FIN报文）。之后客户端进入FIN_WAIT_1状态
2. 服务端收到之后，发送ACK应答报文。之后服务端进入CLOSE_WAIT状态。（此时，服务端能向客户端发数据，但是客户端不能向服务端发数据）
3. 客户端收到服务端ACK报文后，进入FIN_WAIT_2状态
4. 当服务端不再需要连接时，发送释放报文，FIN=1。之后服务端进入last-ack状态
5. 客户端收到服务端的FIN报文后，发送ACK应答报文给服务端。之后客户端进入Time_wait状态。
6. 服务端收到ACK应答报文后，进入close状态。
7. 客户端经过2MSL(最大报文存活时间)一段时间后进入close状态



##### 3、为什么是三次握手？不是两次、四次？

**两次握手**：无法防止历史连接的建立，造成双方资源的浪费。比如客户发出的第一个请求连接报文没有丢失，而是因为在网络上停留太长，服务端连接释放以后才达到。但是这是一个早已失效的报文，服务端误以为这是客户端又一次新的请求，就向客户端发送确认报文，同意连接。如果不进行第三次握手，服务端就会一直等待客户端发信息，导致资源白白浪费。



**四次握手**：三次握手理论上是最少可靠连接了，所以不需要使用更多的通信次数。



##### 4、为什么需要四次挥手？

四次挥手的原因是确保双方都没有数据要发送了。



举个例子：A和B通话，A把话讲完了，跟B说："好啦，我已经没有话说了"，B回复说：”好的，我知道了"。但是此时B还没有把话讲完，接着B吧啦吧啦讲完，最后B说：”好啦，我也讲完啦“，A回答：”知道啦！“。至此双方通话才结束。



##### 5、为什么Time_wait等待时间是2MSL

time_wait等待2MSL，比较合理的解释是：数据包一来一回需要等待2倍的时间。



MSL是报文最大生存时间。

TCP报文是基于IP协议的，IP头中有一个TTL字段，它表示是IP数据包可以经过的最大路由数，没经过一个处理它的路由，此值减1，直到为0，则将数据报丢弃。

MSL与TTL的区别：MSL是以时间为单位，TTL是经过路由跳数。所以MSL的时间要大于TTL消耗为0的时间，以确保报文自然凋亡。

等待2MSL也是为了本次连接发送的报文在网络中自然消亡，避免影响下一次连接中出现旧报文的情况。



等待2MSL也是为了确保最后一个ACK报文到达服务端。这个报文很可能丢失，导致服务端收不到确认报文。所以服务端会超时重传释放报文，客户端就能在2MSL的时间里再次发送确认报文。



##### 6、为什么需要time_wait状态？

主动发起关闭连接的一方，才有time_wait状态。

它是为了保证被动关闭的一方能正确关闭。既保证最后的ACK确认报文能被被动关闭方收到，从而帮助其关闭。



##### 7、如果建立连接，但是客户端突然出现故障怎么办？

TCP有一个保活机制。它的原理是这样的，定义一个时间段，在这个时间段内，没有任何连接活动，TCP保活机制开始起作用。每隔一段时间，发送一个探测报文，如果连续几个探测报文没有响应，则认为当前TCP连接已死亡，接着就关闭此连接。



#### 2、TCP协议如何保证可靠传输？

1. 数据包校验。若数据在传输过程中发生了变化，校验出包有错，则丢弃报文段不给响应。
2. 对失序数据包重排序。TCP报文段采用IP数据报来传输，IP数据报的达到可能会失序，因此TCP报文段也可能会失序。TCP对失序的数据进行重排序，然后上交给应用层。
3. TCP接收端会丢弃重复的数据。
4. 流量控制。TCP连接的每一方都有固定大小的缓冲区，TCP接收端只允许另一方发送接收端缓冲区所能容纳的数据。都接受端来不及处理发送端的数据时，会提示发送方降低发送速率，防止包丢失。TCP是利用滑动窗口来实现流量控制的
5. 拥塞控制。当网络阻塞时，减少数据发送。
6. 超时重传。当TCP发出一个段后，会启动一个定时器，等待目的端确认收到这个报文。如果不能及时确认，将重发这个报文段。
7. ARQ协议。它的基本原理就是每发完一个分组就停止发送，等待对方确认，在收到确认后，再发下一个分组。



##### 1、滑动窗口和流量控制

TCP通过滑动窗口实现流量控制。

滑动窗口是一个流量控制技术。

流量控制是为了控制发送方的速率，保证接收方来得及接受。

接收方的确认报文中的窗口字段可以用来控制发送方的窗口大小，从而影响发送方的发送速率。

将窗口字段设为0，则发送方不能发送数据。



##### 2、拥塞控制以及相关算法

拥塞控制和流量控制不同。拥塞控制是全局性的过程，流量控制是点对点通信量的控制。

在某段时间，若对网络中某一资源的需求超过该资源所能提供的有用部分，网络的性能就会变坏，这种情况就是拥塞。



拥塞控制是为了防止过多的数据注入到网络中，这样就可以使网络中的路由器或链路不至于过载。

拥塞控制是一个全局性的过程，涉及到所有主机、所有路由器，以及与降低网络性能所有有关的因素。

相反流量控制是一个点对点通信量的控制，是个端到端的问题。

流量控制所要做的就是抑制发送端发送数据的速率，以便接收端来的及接收。



为了进行拥塞控制，TCP发送方要维持一个拥塞窗口(cwnd)的状态变量。

拥塞窗口的大小取决于网络的拥塞程度，并且动态变化。

发送方窗口让自己的发送窗口取为拥塞窗口和接收方的接收窗口较小的一个。



TCP拥塞控制采用了四种算法：慢开始、拥塞避免、快重传和快恢复。

**慢开始**：就是由小到大逐渐增大发送窗口。cwnd初始值为1，每经过一个传播轮次，cwnd加倍。

**拥塞避免**：拥塞避免的算法思路是让拥塞窗口cwnd缓慢增大，每经过一个往返时间RTT，就把发送方的cwnd+1

**快重传和快恢复**：

快重传和快恢复(FRR)是一种拥塞控制算法，它能快速恢复丢失的包。

没有快恢复，如果数据包丢失了，TCP将会使用定时器要求传输暂停。在暂停的这段时间内，没有新的或者复制的数据包被发送。

有了快恢复，接收方如果收到一个不按顺序的数据包，立即给发送方发送一个重复确认。如果发送方收到三个重复确认，它会假设确认件指定的数据段丢失，并立即重传这些丢失的数据段。

有了快恢复，就不会因为重传要求暂停被耽误。

当有单独的数据包丢失时，快重传和快恢复能最有效地工作。

当有多个数据包在某一段很短的时间内丢失时，它则不能很有效地工作。 



##### 3、ARQ协议

自动重传请求是OSI模型中，数据链路层和传输层的错误纠正协议之一。

它通过确认和超时两个机制，在不可靠服务的基础上实现可靠的信息传输。

如果发送方发送一段时间内还没收到确认，那通常会重新发送。

ARQ包括停止等待协议ARQ和连续ARQ协议。



**停止等待ARQ协议**

停止等待协议是为实现的可靠的传输，它的基本原理就是没发完一个分组就停止发送，等待对方确认。

如果一段时间还没收到确认回复，说明每发送成功，需要重新发送，直到收到确认后再发下一个分组。

在停止等待协议中，若收到重复分组，则丢失该分组，同时还要发送确认。



优点：简单

缺点：信道利用率低，等待时间长。



**连续ARQ协议**

连续ARQ协议可以提高信道利用率。发送方维持一个发送窗口，凡位于发送窗口内的分组可以连续发出去，而不需要等待对方确认。接收方一般采用累计确认，对按序达到最后一个分组发送确认，表明到这个分组为止的所有分组都已经正确收到了。



优点：信道利用率高

缺点：不能向发送方反映出接收方已经正确收到的所有分组信息。比如，发送方发送了5条消息，中间丢失了第三条（3号）,这是接受方只能对前两个发送确认。发送方无法知道后三个分组的下落，而只好把后三个全部重传一次。



### 三、Http/HTTPS

#### 1、HTTP状态码

1**：表示提示信息，协议处理的中间状态。

2**：表示服务器成功处理了客户端的请求。比如200

3**：重定向，表示资源位置发生了变动，需要客户端重新发起请求。301表示永久重定向；302表示临时重定向

4**：客户端错误，请求报文有误，服务器无法处理。400表示客户端的报文有错；403服务器禁止访问资源；404服务器找不到资源

5**：服务器错误。501表示客户端请求的功能还不支持；502表示服务器作为网关或代理时返回的错误；503表示服务器当前很忙，无法响应。



#### 2、get和post的区别

**作用**

get方法的含义是请求服务器获取资源。

post方法是向指定的资源提交数据，数据放在报文的body里面。



**安全和幂等**

在HTTP协议中，所谓的安全是指请求方法不会破坏服务上的资源

所谓的幂等是指多次执行相同的操作，结果都是相同的



get方法是安全却幂等的，因为它是只读操作，无论操作多少次，服务器上资源都是安全的，并且每次结果都相同。

put方法不是安全的不是幂等的，因为他会修改服务器上的资源，所以不是安全的，并且多次提交就会创建多个资源，所以不死幂等的。



#### 3、HTTP中的长连接和短链接

在HTTP/1.0中默认使用的是短链接。所谓的短链接就是客户端和服务端每进行一次HTTP的操作，就建立一次连接，任务结束就中断连接。

从HTTP/1.1起默认使用长连接，用以保持连接特性。在HTTp协议的响应头加入 connection:keep-alive

在使用长连接的情况下，当一个任务完成之后，客户端和服务端之间用于传输HTTP数据的TCP不会断开连接，客户端继续访问服务器时，会继续使用这条已建立的连接。



#### 4、HTTP与HTTPS有哪些区别？

1. HTTP是超文本传输协议，信息是明文传输的，存在安全风险。HTTPS解决了HTTP不安全的缺陷，在TCP和HTTP之间加入了SSL/TLS安全协议，使得报文能够加密传输
2. HTTP建立相对简单，TCP经过三次握手之后便可进行HTTP的报文传输。而HTTPS与TCP三次握手之后，还需要进行SSL/TLS的握手过程，才可以进入加密报文传输。
3. HTTPS协议需要向CA申请数字证书
4. HTTP的端口是80，HTTPS的端口号是443



#### 5、HTTP/1.1、HTTP/2.0、HTTP/3.0的变化

HTTP/1.1相比HTTP/1.0性能改进

- 使用了长连接的方式
- 支持管道网络传输，只要第一个请求发出去不必等其回来，就可以发第二个请求，减少整体的响应时间



HTTP/2.0相比HTTP/1.1性能改进

- HTTP/2.0支持头部压缩。如果同时发送多个请求，请求头一样或者相似的话，协议会帮你消除重复的部分
- HTTP/2.0不再使用HTTP/1.1那样的纯文本形式的报文，而是采用二进制格式。
- HTTP/2.0支持多路复用，可以在一个连接中并发处理多个请求
- HTTP/2.0支持服务推送，服务器除了返回数据给客户端之外，还可以推送额外的内容给客户端



HTTP/3.0最大的改进就是把HTTP下层的TCP协议改成了UDP！



### 四、常见面试题

#### 1、在浏览器中输入 URL 地址到显示主页的过程？

1. DNS解析。浏览器查询DNS，获取域名对应的IP地址
2. TCP连接。浏览器获得对应的IP地址后，浏览器向服务器请求建立连接，发起三次握手
3. 发送HTTP请求。TCP建立连接后，浏览器向服务器发起HTTP请求。
4. 服务器处理请求并返回HTTP报文。服务器接收到请求，根据路径参数到特定的处理器进行处理，并将处理结果返回给浏览器。
5. 浏览器解析渲染页面。浏览器解析结果并渲染视图
6. 连接结束。



#### 2、DNS解析过程

1. 浏览器会先在缓冲中找域名对应的IP地址，如果有，直接返回
2. 如果没有，则在操作系统本地hosts文件中找，如果有，直接返回。
3. 如果没有，则在本地DNS解析器缓冲中找，如果有，直接返回
4. 如果没有，则在本地DNS服务器找，如果有，则返回
5. 如果没有，则在本地DNS服务器设置的转发器上查询。



DNS查询的两种方式：递归查询和迭代查询

**递归查询**

本地向本地域名服务器的查询一般都是递归查询。本地域名服务器不知道域名所对应的IP地址，它继续向根域名服务器查询，即替主机继续查询。

**迭代查询**

本地域名服务器向根域名服务器的迭代查询

当根域名服务器收到本地域名服务器的查询请求时，要么给出查询的IP地址，要么告诉本地域名服务器向哪一个域名服务器查询。



## 操作系统

### 一、进程与线程

#### 1、进程和线程的概念？以及进程和线程的区别？

进程：是资源分配和调度的基本单位

线程：线程是进程的一个实体，是执行调度的基本单位，有时被称为轻量级进程



**区别**

1. 根本区别：进程是资源分配和调度的基本单位，线程是执行调度的基本单位
2. 共享方面：进程拥有自己独立的地址空间和资源，而线程是共享所属进程的资源
3. 开销方面：创建进程或销毁进程，系统都要为之分配资源或回收资源；因此进程的系统开销比线程大。



#### 2、进程有哪几种状态

![进程状态](D:\github\MyKnowledgeRepository\picture\进程状态.png)

创建

就绪：等待被调度

运行

阻塞：等待资源

结束



**注意**

- 只有就绪和运行可以相互转换，其他都是单向的
- 阻塞状态是由于缺少需要的资源由运行状态转换而来
- 阻塞：是指调用结果返回前，当前线程会被挂起，即阻塞。也可以理解为阻塞就是挂起
- 非阻塞：是指即使调用结果没有返回，也不会挂起当前进程



#### 3、进程间的通信方式有哪几种？

每个进程在用户空间都是相互独立的，一般不能相互访问。但内核空间是每个进程共享的，所以进程之间的通信必须通过内核

1. 管道
   - 它是半双工通信的（单向交替传输），具有固定的读端和写端
   - 它只能在父子进程和兄弟进程间使用
2. 命名管道（FIFO）
   - 去除了父子进程间使用的限制，可以在无关的进程间交换数据
3. 消息队列
   - 消息队列可以独立于读写进程的存在。进程终止时，消息队列及其内容并不会删除
   - 消息队列可以实现消息的随机查询，不一定要先进先出的顺序读取，可以按消息的类型进行读取
4. 共享内存
   - 指两个或多个进程共享一个内存，它是最快的IPC（进程间通信）方式，因为数据不需要在进程间复制
5. 信号量
   - 它是一个计数器，主要实现进程间的互斥与同步，不是用于缓存进程间通信的数据
6. Socket套接字
   - 以上通信方式都是在同一台主机上进程间的通信，Socket可以实现不同主机上进程的通信



### 二、死锁

#### 1、什么是死锁

死锁是指多个进程在运行过程中因争夺资源而造成的一种僵局，如果无外力作用，它们将无法再向前推进。

#### 2、产生死锁的必要条件

- **互斥**：多个进程不能同时使用同一个资源
- **占有和等待**：已经得到某个资源还可以继续申请其他资源，同时不释放已有的资源
- **不可抢占**：资源只能进程自己释放，其他人不可以抢占
- **环路等待**：两个进程获取资源的顺序构成了环路



#### 3、解决死锁的基本方法

1. 预防死锁
   - 破坏互斥条件：
   - 破坏占有和等待条件：只要有一个资源得不到分配，就不给这个进程分配资源
   - 破坏不可抢占条件：当某个进程获得了部分资源，但缺少其他资源，则释放当前的资源
   - 破坏环路等待条件：给每类资源赋予一个编号，按编号递增顺序请求资源，释放则相反
2. 避免死锁
   - 银行家算法
3. 检查死锁
4. 解出死锁
   - 挂起某些死锁进程，并抢占它的资源，将他的资源分配给其他死锁资源
   - 强制撤销部分或者全部死锁进程，回收它的资源
   - 让一个或者多个进程回退到避免死锁的状态



### 三、内存管理

#### 1、物理地址、逻辑地址(虚拟地址)和虚拟内存

**逻辑地址**：我们编程只和逻辑地址打交道。比如在C语言里面，指针里面存储的数值可以理解成内存里的地址，这个地址也就是我们所说的逻辑地址

**物理地址**：就是内存单元真正的地址

**虚拟内存**：计算机管理内存的一种技术，它使得应用程序认为它拥有连续可用的内存空间，而实际上是分成多个物理内存碎片。它的一定意义是使物理内存扩充成了更大的逻辑内存，从而让程序获得更多可用的内存。

比如很大的程序，系统只会先运行它的其中一部分，当用到它的其他部分时，才把它调入进来。这样就可以使得只能运行32M的系统也可以运行64M的程序



操作系统引入虚拟内存，进程持有的虚拟地址会通过CPU的内存管理单元的映射关系，来转换成物理地址，然后再通过物理地址访问真正的内存



### 四、调度算法

#### 1、进程调度算法

- **先来先服务调度算法**

  从就绪队列中选择一个最先进入该队列的进程分配资源，然后一直运行，直到进程退出或被阻塞。

  有利于长作业，不利于短作业。如果长作业先运行，那短作业等待的时间会很长。

- **短作业优先调度算法**

  优先选择运行时间最短的进程来运行。

  长作业可能会被饿死，如果一直有短作业进来，那么长作业一直得不到运行。

- **最短剩余时间优先调度算法**

  当一个新的作业达到时，其整个运行时间与当前进程剩余运行时间作比较，如果新的进程需要时间更少，那么挂起当前进程，运行新的进程。

  存在长作业饥饿的风险

- **时间片轮询调度算法**

  为每个进程分配一个时间片，时间片用完，则换另一个进程执行。

  时间片太短，会导致进程频繁切换；时间片太长，实时性得不到保证

- **优先级调度算法**

  为每个进程分配一个优先级，按优先级进行调度。

  为了防止低优先级的进程饿死，可以随着时间的推移，增加等待进程的优先级。

  

#### 2、页面置换算法

在程序运行过程中，如果要访问的页面不在内存，就会发生缺页中断，从而需要把缺失的页调入内存。如果此时内存已满，就需要把内存中一个页面调出来腾出空间。

页面置换算法和缓存淘汰策略类似，把内存看成是磁盘缓存。当缓存空间已满时，需要淘汰一部分已经存在缓存，从而为新的缓存腾出空间。

- **最佳页面置换算法**

  选择最长时间不再访问的页面，可以保证最低的缺页率。

  这是一个理论算法，因为无法知道一个页面多长时间不被访问。

- **先进先出置换算法**

  选择最先进入的页面

  该算法会导致经常被访问的页面换出，导致缺页率升高

- **最近最久未使用置换算法(LRU)**

  选择最长时间没有被访问的页面

  为了实现LRU，需要在内存中维护一个所有页面的链表，当一个页面访问时，将此页面移到链表头，这样就能保证链表尾的页面是最近最久未使用的。

  每次访问都要更新链表，开销太大。

- **时钟置换算法**

  所有页面都保存在类似时钟的环形链表中，一个表针指向最老的页面

  当发生缺页时，算法会先指向表针所指向的最老页面：

  - 如果该访问位标志是0则淘汰该页面，并将新的页面插入这个位置，然后把表针前移一个位置。

  - 如果该访问位标志是1则清除访问位，并把表针前移一位。重复这个过程，知道找到访问位为0的页面为止。

- **最少使用置换算法**

  选择访问次数最少的那个页面

#### 3、磁盘调度算法

- **先来先服务算法**

  按磁盘先到来的请求进行调度

  优点：公平简单

  缺点：未对寻道优化，导致寻道时间过长

​		如：98 183 37 122 14 124 65 67

![先来先服务](D:\github\MyKnowledgeRepository\picture\磁盘调度-先来先服务.png)

- **最短寻道时间优先算法**

  优先选择当前磁头位置所需寻道时间最短的请求

  优点：寻道时间变短了

  缺点：不公平。如果新到达的请求总是比最近等待的寻道时间短，那将会出现饥饿的现象

  如：98 183 37 122 14 124 65 67

  按最短寻道时间优先，顺序应该是：65 67 37 14 98 122 124 183

  ![最短寻道时间优先](D:\github\MyKnowledgeRepository\picture\磁盘调度-最短寻道时间优先.png)

- **电梯算法**

  磁头在一个方向上移动，访问所有未完成的请求，直到磁头到达该方向的尽头，改变运行方向

  考虑了移动方向，所有磁盘请求都会满足，解决最短寻道时间优先出现的饥饿问题

  如：98 183 37 122 14 124 65 67

  假设先向磁道号减少的方向移动，则有如下顺序：37 14 0  65 67 98 122 124 183

  ![电梯算法](D:\github\MyKnowledgeRepository\picture\磁盘调度-电梯算法.png)

  



